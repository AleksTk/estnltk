{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> Basic NLP toolchain</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> A. Short Introduction and Tutorial for Linguists</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial gives an overview of how to use EstNLTK for the basic analysis of text: splitting it into linguistically meaningful units - words, sentences, - and performing morphological analysis. These steps are necessary in tackling most language-related problems: if we are able to extract words and sentences from text and filter them by lemmas, part-of-speech tags and morphological forms, we can solve numerous tasks, e.g. automatically find example sentences of different grammatical constructions from large corpora, compose word/lemma frequency lists, compare texts in terms of sentence lengths/structures, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important class in Estnltk is Text, which is essentally the main interface for doing everything Estnltk is capable of. To use it, we have to import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from estnltk import Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start working on our text, we have to create a new Text class object of it. Let's use a simple sentence  as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = Text(\"Müüja tatsas rahulikult külmiku juurde.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Müüja tatsas rahulikult külmiku juurde.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text=\"Müüja tatsas rahulikult külmiku juurde.\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic way to use EstNLTK toolchain is to use the tag_layer() method that automatically segments the text and performs morphological analysis. From its output, we can see which layers have been tagged on text, which attributes the layers have and how many elements belong to every layer (column span count). The details about each layer come below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Müüja tatsas rahulikult külmiku juurde.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>normalized_words</td>\n",
       "      <td>normal</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text=\"Müüja tatsas rahulikult külmiku juurde.\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tag_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style=\"color:purple\"> Text segmentation </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most basic tasks of any NLP pipeline is text segmentation: splitting the text into smaller meaningful units - words, sentences, paragraphs, etc. This might seem like a trivial task at first - aren't words separated by spaces and sentences by full stops? And yes, question marks and exclamation marks. However, if we take an existing text, we will see that there are lots of exceptions to these rules. Therefore, EstNLTK has dedicated methods for these kinds of tasks that try to tackle the frequent segmentation issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tokens vs words\n",
    "To make a distinction between properly tagged words (incl. punctuation, abbreviations, e-mail addresses, etc) and elements in text that are separated from each other by whitespace (or not... in case of punctuation), we use the term 'tokens' for the latter. For the most part, tokens overlap with words, but a token might also be a part of a word: in later analysis, tokens are not broken into any smaller parts, but only joined if necessary. If we look at our first example above, we can see that the number of words and tokens is equal. However, there are cases where some tokens are joined into one word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mis aias sa-das 3me sorti s-saia?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>normalized_words</td>\n",
       "      <td>normal</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text=\"Mis aias sa-das 3me sorti s-saia?\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = Text('Mis aias sa-das 3me sorti s-saia?')\n",
    "text.tag_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, in this (quite weird) example sentence, there are 11 tokens but 7 words. To see the tokens (or words for that matter) that have been tagged on text using the tag_layer() method, we can either use the Text object as a typical Python dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>das</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sorti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>saia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.text.Layer at 0x9235a30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we can use the class variable 'tokens' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mis</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aias</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sa</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>das</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3me</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sorti</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>saia</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[Span(Mis, {}),\n",
       "Span(aias, {}),\n",
       "Span(sa, {}),\n",
       "Span(-, {}),\n",
       "Span(das, {}),\n",
       "Span(3me, {}),\n",
       "Span(sorti, {}),\n",
       "Span(s, {}),\n",
       "Span(-, {}),\n",
       "Span(saia, {}),\n",
       "Span(?, {})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get words - smallest meaningful units of language - some tokens might need to be combined. That's why there are layers `compound_tokens` and `normalized_words` which include the tokens that are combined together to create words. This happens when the raw text needs some kind of normalization in order to comply with standard ortography. In addition to the hyphenated words as in the previous example, also some numbers (10,000), e-mail addresses (example@example.com), abbreviations (s.t.) and other entities that have been tagged as separate tokens have to be joined together.\n",
    "\n",
    "We can see and use `words` layer (and all the other layers) the same way as the `tokens` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mis</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aias</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sa-das</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3me</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sorti</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s-saia</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[Span(Mis, {}),\n",
       "Span(aias, {}),\n",
       "Span(sa-das, {}),\n",
       "Span(3me, {}),\n",
       "Span(sorti, {}),\n",
       "Span(s-saia, {}),\n",
       "Span(?, {})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence is a list of sequential words and so the sentence layer is a list of lists of words. This means that first, the text is broken into words, and then, sentence borders are determined so that no sentence border would end up inside a word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example that has multiple sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = Text('''Ka köögis oli kõik endine: vana elektripliit, koorunud värviga ahjutruup ja vanamehe töövorm — rippumas ikka sealsamas ukse küljes nagis. Jälk. Köögi akna all laual oli vanaaegne arvuti. Juba aastaid. Selline kaasaskantav väike kastike, mille klaviatuur ekraani ette kinnitus. See oli sini-valge pildi ja DOS-opsüsteemiga mänguasi.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ka köögis oli kõik endine: vana elektripliit, koorunud värviga ahjutruup ja vanamehe töövorm — rippumas ikka sealsamas ukse küljes nagis. Jälk. Köögi akna all laual oli vanaaegne arvuti. Juba aastaid. Selline kaasaskantav väike kastike, mille klaviatuur ekraani ette kinnitus. See oli sini-valge pildi ja DOS-opsüsteemiga mänguasi.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>normalized_words</td>\n",
       "      <td>normal</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text=\"Ka köögis oli kõik endine: vana elektripliit, koorunud värviga ahjutruup ja vanamehe töövorm — rippumas ikka sealsamas ukse küljes nagis. Jälk. Köögi akna all laual oli vanaaegne arvuti. Juba aastaid. Selline kaasaskantav väike kastike, mille klaviatuur ekraani ette kinnitus. See oli sini-valge pildi ja DOS-opsüsteemiga mänguasi.\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tag_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the text split into sentences by using the `sentences` class variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>Ka</b> <b>köögis</b> <b>oli</b> <b>kõik</b> <b>endine</b><b>:</b> <b>vana</b> <b>elektripliit</b><b>,</b> <b>koorunud</b> <b>värviga</b> <b>ahjutruup</b> <b>ja</b> <b>vanamehe</b> <b>töövorm</b> <b>—</b> <b>rippumas</b> <b>ikka</b> <b>sealsamas</b> <b>ukse</b> <b>küljes</b> <b>nagis</b><b>.</b></td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>Jälk</b><b>.</b></td>\n",
       "      <td>138</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>Köögi</b> <b>akna</b> <b>all</b> <b>laual</b> <b>oli</b> <b>vanaaegne</b> <b>arvuti</b><b>.</b></td>\n",
       "      <td>144</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>Juba</b> <b>aastaid</b><b>.</b></td>\n",
       "      <td>187</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>Selline</b> <b>kaasaskantav</b> <b>väike</b> <b>kastike</b><b>,</b> <b>mille</b> <b>klaviatuur</b> <b>ekraani</b> <b>ette</b> <b>kinnitus</b><b>.</b></td>\n",
       "      <td>201</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>See</b> <b>oli</b> <b>sini-valge</b> <b>pildi</b> <b>ja</b> <b>DOS-opsüsteemiga</b> <b>mänguasi</b><b>.</b></td>\n",
       "      <td>277</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span(Ka, {}),\n",
       "Span(köögis, {}),\n",
       "Span(oli, {}),\n",
       "Span(kõik, {}),\n",
       "Span(endine, {}),\n",
       "Span(:, {}),\n",
       "Span(vana, {}),\n",
       "Span(elektripliit, {}),\n",
       "Span(,, {}),\n",
       "Span(koorunud, {}),\n",
       "Span(värviga, {}),\n",
       "Span(ahjutruup, {}),\n",
       "Span(ja, {}),\n",
       "Span(vanamehe, {}),\n",
       "Span(töövorm, {}),\n",
       "Span(—, {}),\n",
       "Span(rippumas, {}),\n",
       "Span(ikka, {}),\n",
       "Span(sealsamas, {}),\n",
       "Span(ukse, {}),\n",
       "Span(küljes, {}),\n",
       "Span(nagis, {}),\n",
       "Span(., {})],\n",
       "SL[Span(Jälk, {}),\n",
       "Span(., {})],\n",
       "SL[Span(Köögi, {}),\n",
       "Span(akna, {}),\n",
       "Span(all, {}),\n",
       "Span(laual, {}),\n",
       "Span(oli, {}),\n",
       "Span(vanaaegne, {}),\n",
       "Span(arvuti, {}),\n",
       "Span(., {})],\n",
       "SL[Span(Juba, {}),\n",
       "Span(aastaid, {}),\n",
       "Span(., {})],\n",
       "SL[Span(Selline, {}),\n",
       "Span(kaasaskantav, {}),\n",
       "Span(väike, {}),\n",
       "Span(kastike, {}),\n",
       "Span(,, {}),\n",
       "Span(mille, {}),\n",
       "Span(klaviatuur, {}),\n",
       "Span(ekraani, {}),\n",
       "Span(ette, {}),\n",
       "Span(kinnitus, {}),\n",
       "Span(., {})],\n",
       "SL[Span(See, {}),\n",
       "Span(oli, {}),\n",
       "Span(sini-valge, {}),\n",
       "Span(pildi, {}),\n",
       "Span(ja, {}),\n",
       "Span(DOS-opsüsteemiga, {}),\n",
       "Span(mänguasi, {}),\n",
       "Span(., {})]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:purple\">Morphological analysis</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In linguistics, morphology is the identification, analysis, and description of the structure of a given language’s morphemes and other linguistic units, such as root words, lemmas, suffixes, parts of speech etc. When we are processing a morphologically rich language - that Estonian cetrainly is -, getting this kind of information is essential for even the simplest tasks. For example, if we want to find all the mentions of 'maja' from the corpus, we are probably not eager to spell out the 27 different forms that we are interested in ('maja', 'majale', 'majadega'...), but we also do not want to get things like 'majandus' or 'majakas'. If we have morphologically analysed the text, we can just state that we are interested in the lemma 'maja'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estnltk wraps Vabamorf morphological analyzer. Morphological analysis is also performed with no extra hassle when we use the tag_layer() method on our text. When we look at the text object, we can see that there is the morph_analysis layer and it has several attributes: lemma, root, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = Text(\"Aga kõik juhtus iseenesest.\").tag_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Aga kõik juhtus iseenesest.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>normalized_words</td>\n",
       "      <td>normal</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text=\"Aga kõik juhtus iseenesest.\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we can either view the whole analysis as a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Aga</td>\n",
       "      <td>aga</td>\n",
       "      <td>aga</td>\n",
       "      <td>(aga,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kõik</td>\n",
       "      <td>kõik</td>\n",
       "      <td>kõik</td>\n",
       "      <td>(kõik,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>kõik</td>\n",
       "      <td>kõik</td>\n",
       "      <td>(kõik,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juhtus</td>\n",
       "      <td>juhtuma</td>\n",
       "      <td>juhtu</td>\n",
       "      <td>(juhtu,)</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iseenesest</td>\n",
       "      <td>iseenesest</td>\n",
       "      <td>ise_enesest</td>\n",
       "      <td>(ise, enesest)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>(.,)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.text.Layer at 0x9259a10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['morph_analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, using the attributes, we can ask for specific parts of the analysis: lemmas, partofspeechtags, etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['J'], ['P', 'P'], ['V'], ['D'], ['Z']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.partofspeech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of morphological analysis: disambiguation, guessing..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, EstNLTK performs morphological analysis with disambiguation (giving out the analysis that is correct in the context), guessing (if the word is not in the dictionary and cannot be resolved as a compound, it is given a 'guessed' analysis) and proper name analysis. While this kind of output is easy to use because each word has been given an analysis and most words receive only one analysis,  sometimes we want to use the analyser differently. If we want to enhance the recall of the morphological analysis, we can switch off the disambiguation (which, of course, also affects precision). We can also switch off guessing and proper name analysis e.g to verify whether a word exists in Estonian or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the parameters of morphological analyser, we have to use a resolver (a register of taggers). To get to know the parameters of the default resolver that is used by the tag_layer() method, we have to import the default resolver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from estnltk.resolve_layer_dag import DEFAULT_RESOLVER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can see what the default parameters for morph_analysis are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Tags morphological analysis on words.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>layer</th>\n",
       "      <th>attributes</th>\n",
       "      <th>depends_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>VabamorfTagger</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>(lemma, root, root_tokens, ending, clitic, form, partofspeech)</td>\n",
       "      <td>[words, normalized_words]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>compound</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guess</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phonetic</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postmorph_rewriter</th>\n",
       "      <td>VabamorfCorrectionRewriter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propername</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>premorph_layer</th>\n",
       "      <td>normalized_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disambiguate</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.taggers.morf.VabamorfTagger at 0x6d193d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEFAULT_RESOLVER.taggers.rules['morph_analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration tells us that by default, disambiguation, proper name analysis, compound word analysis, and guessing are all applied during morphological analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a resolver, we can write an equivalent code to\n",
    "```python\n",
    "text.tag_layer()\n",
    "```\n",
    "as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from estnltk.resolve_layer_dag import make_resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resolver = make_resolver(\n",
    "                 disambiguate=True,\n",
    "                 guess=True,\n",
    "                 propername=True,\n",
    "                 phonetic=False,\n",
    "                 compound=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = Text(\"Kärbes hulbib mees ja naeris puhub sädelevaid mulle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Kärbes</td>\n",
       "      <td>kärbes</td>\n",
       "      <td>kärbes</td>\n",
       "      <td>(kärbes,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hulbib</td>\n",
       "      <td>hulpima</td>\n",
       "      <td>hulpi</td>\n",
       "      <td>(hulpi,)</td>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mees</td>\n",
       "      <td>mees</td>\n",
       "      <td>mees</td>\n",
       "      <td>(mees,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>(ja,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>naeris</td>\n",
       "      <td>naerma</td>\n",
       "      <td>naer</td>\n",
       "      <td>(naer,)</td>\n",
       "      <td>is</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>puhub</td>\n",
       "      <td>puhuma</td>\n",
       "      <td>puhu</td>\n",
       "      <td>(puhu,)</td>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sädelevaid</td>\n",
       "      <td>sädelev</td>\n",
       "      <td>sädelev</td>\n",
       "      <td>(sädelev,)</td>\n",
       "      <td>id</td>\n",
       "      <td></td>\n",
       "      <td>pl p</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mulle</td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>(mina,)</td>\n",
       "      <td>lle</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>(.,)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.text.Layer at 0x935ca70>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tag_layer(resolver=resolver)['morph_analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the result, with default morphological analysis, all the words get assigned exactly one analysis, but three of them are not correct. The disambiguator has wrongly deleted the correct analyses this time. \n",
    "\n",
    "*Note that this example sentence is a little out of the ordinary and hence the bad performance of disambiguator. The more 'normal' your text is, the better the results.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to change the parameters of morphological analysis, we have to change the default values of the flags to create a customized resolver. For example, to switch off disambiguation, we have to set this value to False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resolver2 = make_resolver(\n",
    "                 disambiguate=False,\n",
    "                 guess=True,\n",
    "                 propername=True,\n",
    "                 phonetic=False,\n",
    "                 compound=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resolver tags only those layers on the text that have not been previously tagged. To see the effect of changed parameters we have to create a new text object or delete the affected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Kärbes</td>\n",
       "      <td>Kärbe</td>\n",
       "      <td>Kärbe</td>\n",
       "      <td>(Kärbe,)</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Kärbes</td>\n",
       "      <td>Kärbes</td>\n",
       "      <td>(Kärbes,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>kärbes</td>\n",
       "      <td>kärbes</td>\n",
       "      <td>(kärbes,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hulbib</td>\n",
       "      <td>hulpima</td>\n",
       "      <td>hulpi</td>\n",
       "      <td>(hulpi,)</td>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mees</td>\n",
       "      <td>mees</td>\n",
       "      <td>mees</td>\n",
       "      <td>(mees,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>mesi</td>\n",
       "      <td>mesi</td>\n",
       "      <td>(mesi,)</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>(ja,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>naeris</td>\n",
       "      <td>naerma</td>\n",
       "      <td>naer</td>\n",
       "      <td>(naer,)</td>\n",
       "      <td>is</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>naeris</td>\n",
       "      <td>naeris</td>\n",
       "      <td>(naeris,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>naeris</td>\n",
       "      <td>naeris</td>\n",
       "      <td>(naeris,)</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>puhub</td>\n",
       "      <td>puhuma</td>\n",
       "      <td>puhu</td>\n",
       "      <td>(puhu,)</td>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sädelevaid</td>\n",
       "      <td>sädelev</td>\n",
       "      <td>sädelev</td>\n",
       "      <td>(sädelev,)</td>\n",
       "      <td>id</td>\n",
       "      <td></td>\n",
       "      <td>pl p</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mulle</td>\n",
       "      <td>mull</td>\n",
       "      <td>mull</td>\n",
       "      <td>(mull,)</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "      <td>pl p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>(mina,)</td>\n",
       "      <td>lle</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>mulle</td>\n",
       "      <td>mulle</td>\n",
       "      <td>(mulle,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>(.,)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.text.Layer at 0x9449970>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del text.morph_analysis\n",
    "text.tag_layer(resolver=resolver2)['morph_analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:purple\"> Examples</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, two simple examples of using EstNLTK basic toolchain for extracting relevant parts of text are presented. Let's use the following short text as our corpus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus. Näiteks pildiraamide meisterdamisel, kus on oluline, et detailide lõikenurgad oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade või puitparketi paigaldamisel.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Finding all different nouns from the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we want to find all different noun lemmas that appear in the text. So, first we have to turn our text into an EstNLTK Text object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_text = Text(\"Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus. Näiteks pildiraamide meisterdamisel, kus on oluline, et detailide lõikenurgad oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade või puitparketi paigaldamisel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus. Näiteks pildiraamide meisterdamisel, kus on oluline, et detailide lõikenurgad oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade või puitparketi paigaldamisel.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text=\"Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus. Näiteks pildiraamide meisterdamisel, kus on oluline, et detailide lõikenurgad oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade või puitparketi paigaldamisel.\")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to let the taggers do their job. Let's use the automatic tag_layer() method for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus. Näiteks pildiraamide meisterdamisel, kus on oluline, et detailide lõikenurgad oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade või puitparketi paigaldamisel.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>normalized_words</td>\n",
       "      <td>normal</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text=\"Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus. Näiteks pildiraamide meisterdamisel, kus on oluline, et detailide lõikenurgad oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade või puitparketi paigaldamisel.\")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text.tag_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can iterate over the lemmas and part-of-speech tags to extract the lemmas that are tagged as nouns. For this, it's easiest to use the zip function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noun_lemmas = []\n",
    "for lemma, postag in zip(my_text.lemma, my_text.partofspeech):\n",
    "    if 'S' in postag:\n",
    "        noun_lemmas += lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB!** Note that both, lemmas and part-of-speech tags for every word are given as a list, that's why we have to check if 'S' is in the postag and we cannot use `append` for adding the lemma to noun_lemmas list without iterating over each word's part-of-speech tags and lemmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nimi',\n",
       " 'nurgasaag',\n",
       " 'tööriist',\n",
       " 'puitdetail',\n",
       " 'lõikamine',\n",
       " 'eesmärk',\n",
       " 'lõikenurk',\n",
       " 'lõikenurk',\n",
       " 'seadistamine',\n",
       " 'võimalus',\n",
       " 'näide',\n",
       " 'pildiraam',\n",
       " 'meisterdamine',\n",
       " 'detail',\n",
       " 'lõikenurk',\n",
       " 'kraad',\n",
       " 'juht',\n",
       " 'nurgasaag',\n",
       " 'tööriist',\n",
       " 'täpsus',\n",
       " 'lõige',\n",
       " 'korratavus',\n",
       " 'osa',\n",
       " 'nurgasaag',\n",
       " 'lõikenurk',\n",
       " 'suund',\n",
       " 'lisa',\n",
       " 'saag',\n",
       " 'saetera',\n",
       " 'kaldenurk',\n",
       " 'seadistamine',\n",
       " 'kasu',\n",
       " 'detail',\n",
       " 'lõikamine',\n",
       " 'nurgasaag',\n",
       " 'laius',\n",
       " 'puulaud',\n",
       " 'puitdetail',\n",
       " 'ristlõige',\n",
       " 'tegemine',\n",
       " 'järkamine',\n",
       " 'näide',\n",
       " 'puitkonstruktsioon',\n",
       " 'ehitamine',\n",
       " 'näide',\n",
       " 'terrassilaud',\n",
       " 'puitparkett',\n",
       " 'paigaldamine']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can easily guess what the specific text was about. If we had a larger corpus, we could make a frequency list and e.g draw some conclusions about topics/word use in a specific publication or variety of language in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Finding all sentences that contain an infinitive verb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we want to extract all sentences containing an infinitive verb form from a corpus. Let's use the same text as in the previous example. Therefore, we have already tagged the necessary layers and we can iterate over the forms and extract sentences that we want to study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infinitive_sentences = []\n",
    "for sent in my_text.sentences:\n",
    "    for form in sent.form:\n",
    "        if 'da' in form:\n",
    "            a = sent.enclosing_text\n",
    "            infinitive_sentences.append(a)\n",
    "            break # not to include the same sentence twice)\n",
    "infinitive_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\"> B. Specific details for programmers: how it works</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:purple\"> Segmentation </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To segment text, the following steps are performed:\n",
    "1. tagging tokens,\n",
    "2. tagging compound tokens,\n",
    "3. tagging words,\n",
    "4. tagging sentences,\n",
    "5. tagging paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens\n",
    "\n",
    "#### General overview\n",
    "\n",
    "Tagging the tokens means that we determine the start and end position of each token, based on whitespace and/or punctuation. There are many whitespace symbols, out of which spaces, tabs, and newlines occur most frequently. When tokens are tagged on the text, the type of whitespace does not matter, but in later analysis, it may be taken into consideration if there was a whitespace between the tokens or not. \n",
    "\n",
    "In the following example, we create a text object with the tokens layer and print out the tokens layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>das</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sorti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>saia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.text.Layer at 0x9454030>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.taggers import TokensTagger\n",
    "text = TokensTagger().tag(Text('Mis aias sa-das 3me sorti s-saia?'))\n",
    "text['tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have 11 tokens in the text. To see the start and end position of each token print out the span list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mis</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aias</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sa</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>das</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3me</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sorti</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>saia</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[Span(Mis, {}),\n",
       "Span(aias, {}),\n",
       "Span(sa, {}),\n",
       "Span(-, {}),\n",
       "Span(das, {}),\n",
       "Span(3me, {}),\n",
       "Span(sorti, {}),\n",
       "Span(s, {}),\n",
       "Span(-, {}),\n",
       "Span(saia, {}),\n",
       "Span(?, {})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Under the hood\n",
    " The `TokensTagger` applies NLTK's [WordPunctTokenizer](http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.regexp.WordPunctTokenizer) to split the text into tokens. The aim is to produce a tokenization where words (\"alphanumeric sequences\") are separated from each other, and where punctuation symbols are also separated from words and from each other. However, `WordPunctTokenizer` leaves punctuation symbols unsplit in some cases, and thus, `TokensTagger` applies an additional post-correction step to ensure that all punctuation symbols are split into single tokens. For instance, the string `\"(1989.a.).\"` is tokenized by  `WordPunctTokenizer` into tokens  `['(', '1989', '.', 'a', '.).']`, and in our post-correction step, it is further split into tokens `['(', '1989', '.', 'a', '.', ')', '.']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compound tokens\n",
    "\n",
    "#### General overview\n",
    "It was said before that although mostly words and tokens overlap with each other, there are cases where several tokens are combined together to form a word in the traditional sense - the smallest meaningful unit of language. There are also special types of text units -- such as emoticons and web and email addresses -- which need to be detected as a whole (as full token sequences) in order to avoid ambiguities in the following processing steps (for instance, a period inside an email address should not be mistaken with a sentence-ending period).\n",
    "\n",
    "Compound token tagger takes care of these cases: it adds `compound_tokens` layer that envelopes the `tokens` layer. It means that every element of the `compound_tokens` layer is a list of `tokens` layer elements - tokens. That makes it easy to glue the tokens together to form the words later on.\n",
    "\n",
    "Compound tokens are formed in a way that they are separate from each other -- no compound token has common tokens with other compound tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>sa</b><b>-</b><b>das</b></td>\n",
       "      <td>hyphenation</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>s</b><b>-</b><b>saia</b></td>\n",
       "      <td>hyphenation</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.text.Layer at 0x9455130>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import CompoundTokenTagger\n",
    "CompoundTokenTagger().tag(text)\n",
    "text['compound_tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, two compound tokens are found, both of which consist of three tokens.\n",
    "\n",
    "Note that the type 'hyphenation' for 's-saia' is incorrect, it should be 'stammer'. It is to be fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the list of lists of tokens that make up the compound tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sa', '-', 'das'], ['s', '-', 'saia']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.compound_tokens.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of compound tokens\n",
    "\n",
    "The main aim of the `CompoundTokenTagger` is to join together tokens that were produced by the splitting logic of `TokensTagger`. `CompoundTokenTagger` addresses different types of compound tokens, and producing most of these tokens can also be switched on/off by flags passed to the constructor. In the following, `CompoundTokenTagger`'s compounding types will be listed, along with the flags that can be used to switch these compounds off (by default, all flags are switched on)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numeric expressions (`tag_numbers`)\n",
    "\n",
    "Tags numeric expressions with decimal separators, numbers with digit group separators, and common date and time formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>02</b><b>.</b><b>02</b><b>.</b><b>2010</b></td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>numeric_date</td>\n",
       "      <td>02.02.2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>22</b><b>:</b><b>55</b></td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>numeric_time</td>\n",
       "      <td>22:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>100</b><b>,</b><b>50</b></td>\n",
       "      <td>38</td>\n",
       "      <td>44</td>\n",
       "      <td>numeric</td>\n",
       "      <td>100,50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>10</b> <b>000</b></td>\n",
       "      <td>52</td>\n",
       "      <td>58</td>\n",
       "      <td>numeric</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span(02, {}),\n",
       "Span(., {}),\n",
       "Span(02, {}),\n",
       "Span(., {}),\n",
       "Span(2010, {})],\n",
       "SL[Span(22, {}),\n",
       "Span(:, {}),\n",
       "Span(55, {})],\n",
       "SL[Span(100, {}),\n",
       "Span(,, {}),\n",
       "Span(50, {})],\n",
       "SL[Span(10, {}),\n",
       "Span(000, {})]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = Text('02.02.2010 22:55 Mati : saad sa mulle 100,50 asemel 10 000 laenata?')\n",
    "text = TokensTagger().tag(text)\n",
    "CompoundTokenTagger(tag_numbers = True).tag(text) # tagging numbers switched on (default setting)\n",
    "text.compound_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the previous example, a compound token can also have attribute `normalized`, which contains a normalized string value for the token. In most cases, the normalization involves removal of whitespace from the string (e.g. `'10 000' => '10000'`). If the pattern that captured the string does not use normalization, then `normalized==None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, if `tag_numbers` is switched on, numeric expressions are also augmented with sign symbols and percentages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>+</b><b>100</b><b>%</b></td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>sign+percentage</td>\n",
       "      <td>+100%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span(+, {}),\n",
       "Span(100, {}),\n",
       "Span(%, {})]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = Text('Mati : +100% kindel, et toon tagasi!!')\n",
    "text = TokensTagger().tag(text)\n",
    "CompoundTokenTagger(tag_numbers = True).tag(text) # tagging numbers switched on (default setting)\n",
    "text.compound_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if more than one compounding rule is applied, the resulting compound token can have multiple compound types. In this case, compound types are separated by `+` (like `sign+percentage` in the previous example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Units x-per-y (`tag_units`)\n",
    "\n",
    "Tags x-per-y style units that follow numeric expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>m</b><b>/</b><b>s</b></td>\n",
       "      <td>57</td>\n",
       "      <td>60</td>\n",
       "      <td>unit</td>\n",
       "      <td>m/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>m</b><b>/</b><b>s</b></td>\n",
       "      <td>102</td>\n",
       "      <td>105</td>\n",
       "      <td>unit</td>\n",
       "      <td>m/s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span(m, {}),\n",
       "Span(/, {}),\n",
       "Span(s, {})],\n",
       "SL[Span(m, {}),\n",
       "Span(/, {}),\n",
       "Span(s, {})]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = Text('Tänase seisuga tuleb ikka suur lohe vaiksema tuule (6-12 m/s) jaoks ja teine väiksem tormikaks (12-20 m/s) võtta…')\n",
    "text = TokensTagger().tag(text)\n",
    "CompoundTokenTagger(tag_units = True).tag(text) # tagging switched on (default setting)\n",
    "text.compound_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Email and www addresses (`tag_email_and_www`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>e</b><b>-</b><b>postiaadressile</b></td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>hyphenation</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>big</b><b>@</b><b>boss</b><b>.</b><b>com</b></td>\n",
       "      <td>29</td>\n",
       "      <td>41</td>\n",
       "      <td>email</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>www</b><b>.</b><b>iamboss</b><b>.</b><b>com</b></td>\n",
       "      <td>66</td>\n",
       "      <td>81</td>\n",
       "      <td>www_address</td>\n",
       "      <td>www.iamboss.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span(e, {}),\n",
       "Span(-, {}),\n",
       "Span(postiaadressile, {})],\n",
       "SL[Span(big, {}),\n",
       "Span(@, {}),\n",
       "Span(boss, {}),\n",
       "Span(., {}),\n",
       "Span(com, {})],\n",
       "SL[Span(www, {}),\n",
       "Span(., {}),\n",
       "Span(iamboss, {}),\n",
       "Span(., {}),\n",
       "Span(com, {})]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = Text('Saada need e-postiaadressile big@boss.com või tule sisesta lehelt www.iamboss.com')\n",
    "text = TokensTagger().tag(text)\n",
    "CompoundTokenTagger(tag_email_and_www = True).tag(text) # tagging switched on (default setting)\n",
    "text.compound_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Common emoticons (`tag_emoticons`)\n",
    "\n",
    "Tags common (Western) emoticons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>:</b><b>)</b><b>)</b></td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>emoticon</td>\n",
       "      <td>:))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>:</b><b>-</b><b>)</b></td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>emoticon</td>\n",
       "      <td>:-)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span(:, {}),\n",
       "Span(), {}),\n",
       "Span(), {})],\n",
       "SL[Span(:, {}),\n",
       "Span(-, {}),\n",
       "Span(), {})]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = Text('Maja on fantastiline :)) ja mõte on hea :-)')\n",
    "text = TokensTagger().tag(text)\n",
    "CompoundTokenTagger(tag_emoticons = True).tag(text) # tagging switched on (default setting)\n",
    "text.compound_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Names preceded by initials (`tag_initials`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>M</b><b>.</b> <b>Port</b></td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>name_with_initial</td>\n",
       "      <td>M. Port</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>M</b><b>.</b> <b>Meelak</b></td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>name_with_initial</td>\n",
       "      <td>M. Meelak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>O</b><b>.</b> <b>Zhemtshugov</b></td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>name_with_initial</td>\n",
       "      <td>O. Zhemtshugov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>R</b><b>.</b><b>-</b><b>L</b><b>.</b> <b>Kivi</b></td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "      <td>name_with_initial</td>\n",
       "      <td>R.-L. Kivi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span(M, {}),\n",
       "Span(., {}),\n",
       "Span(Port, {})],\n",
       "SL[Span(M, {}),\n",
       "Span(., {}),\n",
       "Span(Meelak, {})],\n",
       "SL[Span(O, {}),\n",
       "Span(., {}),\n",
       "Span(Zhemtshugov, {})],\n",
       "SL[Span(R, {}),\n",
       "Span(., {}),\n",
       "Span(-, {}),\n",
       "Span(L, {}),\n",
       "Span(., {}),\n",
       "Span(Kivi, {})]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = Text('(arhitektid M. Port, M. Meelak, O. Zhemtshugov, R.-L. Kivi)')\n",
    "text = TokensTagger().tag(text)\n",
    "CompoundTokenTagger(tag_initials = True).tag(text) # tagging switched on (default setting)\n",
    "text.compound_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Common abbreviations (`tag_abbreviations`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>Nt</b><b>.</b></td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>non_ending_abbreviation</td>\n",
       "      <td>Nt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>Vana</b><b>-</b><b>Hiina</b></td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>hyphenation</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>saj</b><b>.</b></td>\n",
       "      <td>64</td>\n",
       "      <td>68</td>\n",
       "      <td>abbreviation</td>\n",
       "      <td>saj.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>e</b><b>.</b> <b>m</b><b>.</b> <b>a</b><b>.</b></td>\n",
       "      <td>69</td>\n",
       "      <td>77</td>\n",
       "      <td>abbreviation</td>\n",
       "      <td>e.m.a.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span(Nt, {}),\n",
       "Span(., {})],\n",
       "SL[Span(Vana, {}),\n",
       "Span(-, {}),\n",
       "Span(Hiina, {})],\n",
       "SL[Span(saj, {}),\n",
       "Span(., {})],\n",
       "SL[Span(e, {}),\n",
       "Span(., {}),\n",
       "Span(m, {}),\n",
       "Span(., {}),\n",
       "Span(a, {}),\n",
       "Span(., {})]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = Text('Nt. hädas oli juba Vana-Hiina suurim ajaloolane Sima Qian (II—I saj. e. m. a.).')\n",
    "text = TokensTagger().tag(text)\n",
    "CompoundTokenTagger(tag_abbreviations = True).tag(text) # tagging switched on (default setting)\n",
    "text.compound_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbreviations are divided into two categories: 1) `non_ending_abbreviation`-s which most likely do not end the sentence (usually it can be expected that some sentence content follows them), and 2) `abbreviation`-s which can also appear at the end of the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Morphological case endings (`tag_case_endings`)\n",
    "\n",
    "Tags morphological case endings preceded by single tokens, and also by compound tokens:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>10</b> <b>000</b><b>-</b><b>st</b></td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>numeric+hyphenation+case_ending</td>\n",
       "      <td>10000-st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>LinkedIn</b> <b>'</b><b>i</b></td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>case_ending</td>\n",
       "      <td>LinkedIn'i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>SKT</b> <b>-</b><b>st</b></td>\n",
       "      <td>60</td>\n",
       "      <td>67</td>\n",
       "      <td>case_ending</td>\n",
       "      <td>SKT-st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>workshop</b> <b>'</b> <b>e</b></td>\n",
       "      <td>78</td>\n",
       "      <td>90</td>\n",
       "      <td>case_ending</td>\n",
       "      <td>workshop'e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span(10, {}),\n",
       "Span(000, {}),\n",
       "Span(-, {}),\n",
       "Span(st, {})],\n",
       "SL[Span(LinkedIn, {}),\n",
       "Span(', {}),\n",
       "Span(i, {})],\n",
       "SL[Span(SKT, {}),\n",
       "Span(-, {}),\n",
       "Span(st, {})],\n",
       "SL[Span(workshop, {}),\n",
       "Span(', {}),\n",
       "Span(e, {})]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = Text(\"10 000-st LinkedIn 'i kontaktist mitte üks ei hoolinud meie SKT -st, aga meie workshop ' e väisasid küll.\")\n",
    "text = TokensTagger().tag(text)\n",
    "CompoundTokenTagger(tag_case_endings = True).tag(text) # tagging switched on (default setting)\n",
    "text.compound_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyphenations (`tag_hyphenations`)\n",
    "\n",
    "If consecutive tokens are separated by hyphen symbol, and these tokens consist of letters, then these tokens are joined together as forming a \"hyphenated word\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>vää</b><b>-</b><b>ää</b><b>-</b><b>ääga</b></td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>hyphenation</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>ka</b><b>-</b><b>su</b><b>-</b><b>lik</b></td>\n",
       "      <td>39</td>\n",
       "      <td>48</td>\n",
       "      <td>hyphenation</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span(vää, {}),\n",
       "Span(-, {}),\n",
       "Span(ää, {}),\n",
       "Span(-, {}),\n",
       "Span(ääga, {})],\n",
       "SL[Span(ka, {}),\n",
       "Span(-, {}),\n",
       "Span(su, {}),\n",
       "Span(-, {}),\n",
       "Span(lik, {})]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = Text('See on vää-ää-ääga huvitav, aga kas ka ka-su-lik?!')\n",
    "text = TokensTagger().tag(text)\n",
    "CompoundTokenTagger(tag_hyphenations=True).tag(text) # tagging switched on (default setting)\n",
    "text.compound_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the language phenomen covered by \"hyphenation compound tokens\" is actually wider: in addition to hyphenated words, it also covers stretched out words (such as _'vää-ää-ääga'_) and syllabified words (such as _'ka-su-lik'_)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technical details\n",
    "\n",
    "**`CompoundTokenTagger`** combines the knowledge about token spans (produced by `TokensTagger`), and the knowledge about the original tokenization (i.e. which text units were separated by whitespace in the original text) to determine which tokens should be joined into compound ones. This process consists of the following steps:\n",
    "\n",
    "1. **Tagging of _strict tokenization hints_**: `estnltk.taggers.RegexTagger` is applied to find non-overlapping text spans that correspond to tokens that need to be joined. In this phase, the following types of compounding hints are tagged:\n",
    "\n",
    "      1.1 `numeric` expressions like numbers with decimal separators (e.g. `'10,5'`), numbers with digit group separators (e.g. `'10 000 000'`), and common formats of numeric dates (`'02.02.2010'`) and times (`'22:55'`);      \n",
    "      1.2 \"X-per-Y\" style `units` (e.g. speed units like `'km/h'` or `'MB/s'`, and emission units like `'g/km'`);          \n",
    "      1.3 `emails` and `www_addresses` (like `'big@boss.com'` or `'www.neti.ee'` or `'https://www.postimees.ee'`);  \n",
    "      1.4 commonly used `emoticons` (like `:)`, `:D` or  `:-P`);   \n",
    "      1.5 `names_with_initial` (like `'A. H. Tammsaare'` or `'J.K. Rowling'`);   \n",
    "      1.6 commonly used `abbreviations` (like `'s.o.'`, `'st'`, or `'a.'`);  \n",
    "            \n",
    "2. **Creating an initial list of compound tokens** based on the _strict tokenization hints_ (produced in the previous step), and  _the hyphenation logic_. \n",
    "\n",
    "      2.1 _Strict tokenization hints_ are used in the following way: if a hint's text span starts _exactly_ where a token starts, and hint's text span ends _exactly_ where a sequence of tokens ends, then, and only then, a compound token is created from the sequence of tokens covered by the hint. So, no compound token is created if hint's text span either starts or ends at the middle of a token;\n",
    "      \n",
    "      2.2. _Hyphenation logic_ collects consecutive tokens that have a hyphenation symbol '-', but no space in between them, and creates corresponding compound tokens. For instance, the token sequence `['v','-','v','-','v','-','ve','-','ve','-','veri']` (originating from the string `'v-v-v-ve-ve-veri'`) will be joined into a compound token;\n",
    "\n",
    "3. **Tagging of _non-strict tokenization hints_**: `estnltk.taggers.RegexTagger` is applied with a second set of patterns to find non-overlapping text spans that hint about potential joining places of tokens and/or compound tokens (from the step 2). The following types of compounding hints are tagged:\n",
    "\n",
    "      3.1. morphological `case_endings` preceded by single tokens (e.g. `\"Palace'ist\"`), and compound tokens (e.g. in numeric expressions like `\"10 000-ni\"`, or in web addresses like `\"www.neti.ee-st\"`);        \n",
    "      3.2 `sign` symbols (-, +, ±) followed by numbers (like in `'+20'` or `'-10 000'`);        \n",
    "      3.3 `percentage` symbols preceded by numbers (like in `'20%'` or `'30,567%'`);    \n",
    "\n",
    "4. ** Extending tokens and compound tokens based on the _non-strict tokenization hints_ (produced in the previous step)**.\n",
    "\n",
    "      _Non-strict tokenization hints_ differ from the _strict ones_ in a way that they leave one end of the hint's span (either left or right) unspecified. For instance, the pattern detecting `case_endings` leaves left side of the sequence unspecified: the left side could be a single token, or a compound_token with an unspecified length. The pattern only describes the end of the sequence, which must consist of a letter (or a number) followed by a case separator (like `'′'` or `'-'`), and finally followed by a case ending in a single token (like `'st'` or `'ni'`). In similar manner, the pattern adding signs to numbers leaves open the right side (the actual extent of the numeric expression);\n",
    "      \n",
    "      Note: as long as the regions described by the hints do not overlap, one token or compound token can be modified by multiple hints, e.g. `sign` symbol could be added before a numeric token, and `percentage` symbol could be added after that token;\n",
    "      \n",
    "5. ** Creating the layer `'compound_tokens'` based on the compound tokens aquired in the previous steps.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenization hints\n",
    "\n",
    "Basically, each tokenization hint is a result of applying a regular expression over the original text. All patterns producing tokenization hints are in the module `estnltk.taggers.text_segmentation.patterns`.  The file contains lists of records in the `estnltk.taggers.RegexTagger` vocabulary format. For instance, a pattern for capturing simple email addresses is conveyed by the following entry:\n",
    "\n",
    "         {'comment': '*) Pattern for detecting common e-mail formats;',\n",
    "          'example': 'bla@bla.bl',\n",
    "          'pattern_type': 'email',\n",
    "          '_group_': 1,\n",
    "          '_priority_': (0, 0, 1),\n",
    "          '_regex_pattern_': r'([{ALPHANUM}_.+-]+@[{ALPHANUM}-]+\\.[{ALPHANUM}-.]+)'.format(**MACROS),\n",
    "          'normalized': 'lambda m: None'},\n",
    "          \n",
    "Attribute `'comment'` is used to give a short description of the pattern, and `'example'` exemplifies a string captured by the pattern. Although these attributes are not mandatory, it is highly advisable to use them when adding new entries, as it helps to maintain interpretably of the vocabulary file.\n",
    "\n",
    "Attribute `'pattern_type'` is mandatory and expresses the category of the compound token. If a compound token is created based on the tokenization hint, then compound token's attribute `'type'` will get its value from the `'pattern_type'`. Note that the name should not contain symbol  `'+'`, because during the application of _non-strict tokenization hints_, `'type'`-s of several compound tokens are merged, and `'+'` is used as a separator character.\n",
    "\n",
    "If `'pattern_type'` of a _strict tokenization hint_ (a \"1st level pattern\") contains prefix `negative:` (e.g. `'negative:ps-abbreviation'`), then the pattern does not produce any tokenization hints, but it is used instead to prevent other patterns from matching. Basically, it describes strings that are similar to ones captured by some positive pattern, and that should not be captured (as they would be false positives). For instance, a negative pattern is created to capture temperature units followed by sentence ending (e.g. ... _kuumarekord on 38**º C.** Talved on_ ... ) in order to prevent patterns capturing names with initials from matching (e.g. capturing _**C. Talved**_ as a name with an initial). Note that a negative pattern must have `'_priority_'` value smaller than `'_priority_'` values of patterns it prevents from matching.\n",
    "\n",
    "Attribute `'_priority_'` describes priority of the pattern: smaller the value, higher the priority. Priority comes into play when multiple patterns capture the same string region, or there are overlaps in captured regions. In such cases, the string captured by the pattern with the highest priority (lowest priority value) will be chosen. In case of equal `'_priority_'` values, the default strategy is to choose the longest string.\n",
    "\n",
    "Attribute `'_regex_pattern_'` gives the regular expression for capturing the string of the compound token. It can be a regular expression pattern string, but also a pre-compiled regular expression object. In the previous example, the pattern string is given as a template, in which named placeholders (`{ALPHANUM}`) are filled in using the information from the dictionary `MACROS`.\n",
    "\n",
    "Attribute `'_group_'` gives the number (or the name) of the group captured by the regular expression which represents the _actual compound token_. So, the regular expression can also describe compound tokens with some added context, and the group number can be used to pick out the _compound token_.\n",
    "\n",
    "And finally, attribute `'normalized'` gives a lambda function (or a string describing a lambda function) which is to be applied on a match object to produce a normalized version of the captured string. If normalization is not necessary, the value can be `'lambda m: None'` (like in the previous example).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparisons to compounding rules used in the EstSyntax pre-processing module\n",
    "\n",
    "On building EstNLTK's compounding rules, the tokenization postcorrection rules of the pre-processing module of EstSyntax (available at https://github.com/EstSyntax/preprocessing-module and https://github.com/kristiinavaik/ettenten-eeltootlus) were taken as a starting point. A number of these rules were also reimplemented in EstNLTK, but not all of them. The following table compares EstNLTK's and EstSyntax's token compounding approaches:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type of compound token | Examples | Compounded by EstSyntax <br> preprocessing module? \\*\\* | Compounded by EstNLTK <br> 1.6?\n",
    "--- | --- | --- | --- | ---\n",
    "**`numerics`** `with digit grouping` | `20 000` | yes | yes\n",
    "`numerics with decimal separator` | `3 , 5` <br> `3,5` <br> `3.5` | yes | yes\n",
    "`numerics followed by period` <br> (ordinal numbers) | `1995.`  <br> `1 .` | yes | yes\n",
    "`numerics with sign` | `-3` <br> `± 500` | yes | yes\n",
    "`numerics with percentage sign` | `10 %` <br> `25%` | yes | yes\n",
    "`common` **`date and time patterns`** | `15. 04. 2005` <br> `16:30` | yes\\*\\* | yes\n",
    "**`ranges`** `of numbers` | `40 000-45 000` <br> `8 - 16%` <br> `14.00 – 16.30` <br> `2 ... 3 , 5` | yes | no\n",
    "**`scales/ratios`** `of numbers` | `1 , 5 : 0 , 5` <br> `0 : 4` | yes | no\n",
    "**`proportions`** `of numbers` | `5 36-st` | yes | no\n",
    "`(binary)` **`arithmetic operations`** | `17± 5` <br> `3 x 15` | yes | no\n",
    "**`arithmetic expressions`** and <br> formula-like expressions | `2 + 3 = 5` <br> `n = 122` | yes | no\n",
    "**`units`** `\"X-per-Y\"`  | `km / h` <br> `g/km` | yes | yes\n",
    "`quantities with units` | `60 km / h` <br> `2,3 h/m` <br> `1,0 mM` | yes | no\n",
    "`1-letter` **`abbreviations`** <br> `with numbers`  | `E 961` <br> `I 26` | yes | yes\n",
    "`common` **`abbreviations`** <br> | `s. o.` <br> `Nt .` <br> `Jr.` | yes | yes\n",
    "`names with` **`initials`** | `A . H . Tammsaare` <br> `A. H. Tammsaare` <br> `D . Trump` | yes | yes\n",
    "`names with` **`ampersands`** | `Simon &amp; Schusteri` | yes | no\n",
    "`morphological` **`case endings`** | `4000-le` <br> `SKT-st` <br> `workshop ' e` | yes | yes\n",
    "**`email addresses`** | `big@boss.com` <br> `user [ -at- ] dumb.com` | yes\\*\\* | yes\n",
    "**`www addresses`** | `http : //www.offa.org/ stats` <br> `www.esindus.ee/korteriturg` | yes\\*\\* | yes\n",
    "`common` **`emoticons`** | `:-)` <br> `:)))` | no | yes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\*\\* The most important difference between EstNLTK's and EstSyntax's token compounding approaches is the following. EstSyntax aims to provide postcorrections -- that is, to fix tokenization that has been broken (e.g. by an earlier automatic tokenization). So, in many cases, EstSyntax's patterns focus only broken cases and do not specifically address correct cases (e.g. email address patterns can capture address `\"dumb . user [ -at- ] dumb.com\"`, but there is no pattern for capturing address `\"big@boss.com\"`). EstNLTK, on the other hand, aims to cover correctly tokenized cases, and also to provide postcorrections where necessary (e.g. both email addresses `\"dumb . user [ -at- ] dumb.com\"` and `\"big@boss.com\"` are captured)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words\n",
    "To get words - smallest meaningful units of language - the outputs of tokens tagger and compound token tagger have to be combined. This is done by word tokenizer and it is quite straightforward: every compound token is a word, and every token that is not a part of a compound token is also a word. The words are tagged on the raw text the same way as the tokens were. It means that the `words` layer does not depend on `tokens` layer or `compound_tokens` layer and so these layers may be deleted after the words are tagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>See</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vää-ää-ääga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>huvitav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka-su-lik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.text.Layer at 0x9450510>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import WordTokenizer\n",
    "WordTokenizer().tag(text)\n",
    "text['words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences\n",
    "The sentence tagger first looks for the sentence end points in the raw text and then leaves out all the points that are not the ending points of the words. The remaining points are used to split the list of words into the list of sentences. This avoids many common mistakes of sentence tagging provided that the compound token tagger has done a good job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>Esimene</b> <b>lõik</b><b>.</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>Teine</b> <b>lause</b><b>.</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>Teine</b> <b>lõik</b><b>.</b></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.text.Layer at 0x925d870>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import SentenceTokenizer\n",
    "text = Text('''Esimene lõik. Teine lause.\n",
    "\n",
    "Teine lõik.''')\n",
    "text.tag_layer(['words'])\n",
    "SentenceTokenizer().tag(text)\n",
    "text['sentences']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paragraphs\n",
    "A paragraph is a list of sequential sentences. The process of tagging paragraphs is similar to the sentence tagging. First the possible ending points of the paragraphs are searched from the raw text and then the list of the sentences is split into the list of paragraphs taking into account only those points that are ending points of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>paragraphs</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>sentences</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>Esimene lõik.</b> <b>Teine lause.</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>Teine lõik.</b></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.text.Layer at 0x94599d0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import ParagraphTokenizer\n",
    "ParagraphTokenizer().tag(text)\n",
    "text['paragraphs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:purple\">Morphological analysis</span>\n",
    "The core of morphological analysis is the VabamorfTagger. Before VabamorfTagger we run the WordNormalizingTagger that creates a 'normalized_words' layer. VabamorfTagger then uses 'words' and 'normalized_words' as the input layers and tags the 'morph_analysis' layer on the 'words' layer.\n",
    "### Premorph\n",
    "Currently we have a WordNormalizingTagger which tags words with extra hyphens and stammer but I think this functionality should be incorporated into CompoundTokenTagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>normalized_words</td>\n",
       "      <td>normal</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sa-das</td>\n",
       "      <td>sadas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s-saia</td>\n",
       "      <td>saia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.text.Layer at 0x925dd30>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import WordNormalizingTagger\n",
    "text = Text('Mis aias sa-das 2te sorti s-saia?')\n",
    "text.tag_layer(['words']) \n",
    "WordNormalizingTagger().tag(text)\n",
    "text['normalized_words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VabamorfTagger\n",
    "The central part of the VabamorfTagger is the Vabamorf of estnltk. VabamorfTagger creates a morphological analysis layer on the words layer. This layer is ambiguous. It means that one word can have more than one analysis. Inside the VabamorfTagger the output of Vabamorf is corrected for some words that contain numbers. The result is written to the 'morph_analysis' layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mis</td>\n",
       "      <td>mis</td>\n",
       "      <td>mis</td>\n",
       "      <td>(mis,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>mis</td>\n",
       "      <td>mis</td>\n",
       "      <td>(mis,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aias</td>\n",
       "      <td>aed</td>\n",
       "      <td>aed</td>\n",
       "      <td>(aed,)</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sa-das</td>\n",
       "      <td>sadama</td>\n",
       "      <td>sada</td>\n",
       "      <td>(sada,)</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2te</td>\n",
       "      <td>2.</td>\n",
       "      <td>2.</td>\n",
       "      <td>(2.,)</td>\n",
       "      <td>te</td>\n",
       "      <td></td>\n",
       "      <td>pl g</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>adt</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sorti</td>\n",
       "      <td>sort</td>\n",
       "      <td>sort</td>\n",
       "      <td>(sort,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s-saia</td>\n",
       "      <td>sai</td>\n",
       "      <td>sai</td>\n",
       "      <td>(sai,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>(?,)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.text.Layer at 0x9459590>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import VabamorfTagger\n",
    "VabamorfTagger().tag(text)\n",
    "text['morph_analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example we swich off vabamorf corrector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mis</td>\n",
       "      <td>mis</td>\n",
       "      <td>mis</td>\n",
       "      <td>(mis,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>mis</td>\n",
       "      <td>mis</td>\n",
       "      <td>(mis,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aias</td>\n",
       "      <td>aed</td>\n",
       "      <td>aed</td>\n",
       "      <td>(aed,)</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sa-das</td>\n",
       "      <td>sadama</td>\n",
       "      <td>sada</td>\n",
       "      <td>(sada,)</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2te</td>\n",
       "      <td>2sina</td>\n",
       "      <td>2_sina</td>\n",
       "      <td>(2, sina)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>pl g</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sorti</td>\n",
       "      <td>sort</td>\n",
       "      <td>sort</td>\n",
       "      <td>(sort,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s-saia</td>\n",
       "      <td>sai</td>\n",
       "      <td>sai</td>\n",
       "      <td>(sai,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>(?,)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.text.Layer at 0x9459530>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del text.morph_analysis\n",
    "VabamorfTagger(postmorph_rewriter=None).tag(text)\n",
    "text['morph_analysis']"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
