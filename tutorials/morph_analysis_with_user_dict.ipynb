{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological analysis with user dictionary\n",
    "\n",
    "If you are to analyse non-standard Estonian texts (such as the Internet language, transcribed spoken language, or written texts heavily influenced by regional dialects), the standard morphological analyser will probably have suboptimal performance. \n",
    "But if the errors are regular enough, you can compose (either manually or semi-automatically) a user dictionary with corrections.\n",
    "The dictionary is then used to rewrite 'morph_analysis' layer in a way that words with erroneous analyses will have new analyses from the dictionary.\n",
    "\n",
    "Let's consider an example sentence from Internet language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_str = \"see onn hädavajalik vajd merel, xhus vxi metsas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, try to analyse it with the standard morphological analyser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>see</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>(see,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>onn</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>(onn,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>häda_vajalik</td>\n",
       "      <td>(häda, vajalik)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vajd</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>vajd</td>\n",
       "      <td>vajd</td>\n",
       "      <td>(vajd,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>merel</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>meri</td>\n",
       "      <td>meri</td>\n",
       "      <td>(meri,)</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>(,,)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xhus</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>xhu</td>\n",
       "      <td>xhu</td>\n",
       "      <td>(xhu,)</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vxi</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>vxi</td>\n",
       "      <td>vxi</td>\n",
       "      <td>(vxi,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>metsas</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "      <td>mets</td>\n",
       "      <td>mets</td>\n",
       "      <td>(mets,)</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span(see, {'clitic': '', 'ending': '0', 'form': 'sg n', 'lemma': 'see', 'partofspeech': 'P', 'root': 'see', 'root_tokens': ('see',)})],\n",
       "SL[Span(onn, {'clitic': '', 'ending': '0', 'form': 'sg n', 'lemma': 'onn', 'partofspeech': 'S', 'root': 'onn', 'root_tokens': ('onn',)})],\n",
       "SL[Span(hädavajalik, {'clitic': '', 'ending': '0', 'form': 'sg n', 'lemma': 'hädavajalik', 'partofspeech': 'A', 'root': 'häda_vajalik', 'root_tokens': ('häda', 'vajalik')})],\n",
       "SL[Span(vajd, {'clitic': '', 'ending': '0', 'form': 'sg n', 'lemma': 'vajd', 'partofspeech': 'S', 'root': 'vajd', 'root_tokens': ('vajd',)})],\n",
       "SL[Span(merel, {'clitic': '', 'ending': 'l', 'form': 'sg ad', 'lemma': 'meri', 'partofspeech': 'S', 'root': 'meri', 'root_tokens': ('meri',)})],\n",
       "SL[Span(,, {'clitic': '', 'ending': '', 'form': '', 'lemma': ',', 'partofspeech': 'Z', 'root': ',', 'root_tokens': (',',)})],\n",
       "SL[Span(xhus, {'clitic': '', 'ending': 's', 'form': 'sg in', 'lemma': 'xhu', 'partofspeech': 'S', 'root': 'xhu', 'root_tokens': ('xhu',)})],\n",
       "SL[Span(vxi, {'clitic': '', 'ending': '0', 'form': 'sg g', 'lemma': 'vxi', 'partofspeech': 'S', 'root': 'vxi', 'root_tokens': ('vxi',)})],\n",
       "SL[Span(metsas, {'clitic': '', 'ending': 's', 'form': 'sg in', 'lemma': 'mets', 'partofspeech': 'S', 'root': 'mets', 'root_tokens': ('mets',)})]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text(text_str)\n",
    "text.tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the results were not so good.\n",
    "\n",
    "But we can create an user dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from estnltk.taggers.morph.userdict_tagger import UserDictTagger\n",
    "\n",
    "# Create new user dictionary (stores words in case insensitive manner)\n",
    "userdict = UserDictTagger(ignore_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and populate it with correct analyses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "userdict.add_word('onn', [{'form': 'b', 'root': 'ole', 'ending':'0', 'partofspeech': 'V', 'clitic':''}] )\n",
    "userdict.add_word('vajd', [{'form': '', 'root': 'vaid', 'ending':'0', 'partofspeech': 'D', 'clitic':''}] )\n",
    "userdict.add_word('xhus', [{'form': 'sg in', 'root': 'õhk', 'ending':'s', 'partofspeech': 'S', 'clitic':''}] )\n",
    "userdict.add_word('vxi', [{'form': '', 'root': 'või', 'ending':'0', 'partofspeech': 'J', 'clitic':''}] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and apply it to correct the analyses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>see</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>(see,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>onn</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>(ole,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>häda_vajalik</td>\n",
       "      <td>(häda, vajalik)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vajd</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>vaid</td>\n",
       "      <td>vaid</td>\n",
       "      <td>(vaid,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>merel</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>meri</td>\n",
       "      <td>meri</td>\n",
       "      <td>(meri,)</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>(,,)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xhus</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>õhk</td>\n",
       "      <td>õhk</td>\n",
       "      <td>(õhk,)</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vxi</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>või</td>\n",
       "      <td>või</td>\n",
       "      <td>(või,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>metsas</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "      <td>mets</td>\n",
       "      <td>mets</td>\n",
       "      <td>(mets,)</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span(see, {'clitic': '', 'ending': '0', 'form': 'sg n', 'lemma': 'see', 'partofspeech': 'P', 'root': 'see', 'root_tokens': ('see',)})],\n",
       "SL[Span(onn, {'clitic': '', 'ending': '0', 'form': 'b', 'lemma': 'olema', 'partofspeech': 'V', 'root': 'ole', 'root_tokens': ('ole',)})],\n",
       "SL[Span(hädavajalik, {'clitic': '', 'ending': '0', 'form': 'sg n', 'lemma': 'hädavajalik', 'partofspeech': 'A', 'root': 'häda_vajalik', 'root_tokens': ('häda', 'vajalik')})],\n",
       "SL[Span(vajd, {'clitic': '', 'ending': '0', 'form': '', 'lemma': 'vaid', 'partofspeech': 'D', 'root': 'vaid', 'root_tokens': ('vaid',)})],\n",
       "SL[Span(merel, {'clitic': '', 'ending': 'l', 'form': 'sg ad', 'lemma': 'meri', 'partofspeech': 'S', 'root': 'meri', 'root_tokens': ('meri',)})],\n",
       "SL[Span(,, {'clitic': '', 'ending': '', 'form': '', 'lemma': ',', 'partofspeech': 'Z', 'root': ',', 'root_tokens': (',',)})],\n",
       "SL[Span(xhus, {'clitic': '', 'ending': 's', 'form': 'sg in', 'lemma': 'õhk', 'partofspeech': 'S', 'root': 'õhk', 'root_tokens': ('õhk',)})],\n",
       "SL[Span(vxi, {'clitic': '', 'ending': '0', 'form': '', 'lemma': 'või', 'partofspeech': 'J', 'root': 'või', 'root_tokens': ('või',)})],\n",
       "SL[Span(metsas, {'clitic': '', 'ending': 's', 'form': 'sg in', 'lemma': 'mets', 'partofspeech': 'S', 'root': 'mets', 'root_tokens': ('mets',)})]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userdict.tag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Voilà !_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
