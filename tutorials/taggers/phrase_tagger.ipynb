{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PhraseTagger\n",
    "`PhraseTagger` can be used to tag sequencial attribute values of a layer. The result is an enveloping layer.\n",
    "Let's create a Text object with `morph_analysis` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Eestimaal</td>\n",
       "      <td>Eestimaa</td>\n",
       "      <td>Eesti_maa</td>\n",
       "      <td>(Eesti, maa)</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tunnevad</td>\n",
       "      <td>tundma</td>\n",
       "      <td>tund</td>\n",
       "      <td>(tund,)</td>\n",
       "      <td>vad</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>inimesed</td>\n",
       "      <td>inimene</td>\n",
       "      <td>inimene</td>\n",
       "      <td>(inimene,)</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>palju</td>\n",
       "      <td>palju</td>\n",
       "      <td>palju</td>\n",
       "      <td>(palju,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>puudust</td>\n",
       "      <td>puudus</td>\n",
       "      <td>puudus</td>\n",
       "      <td>(puudus,)</td>\n",
       "      <td>t</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>päikesest</td>\n",
       "      <td>päikene</td>\n",
       "      <td>päikene</td>\n",
       "      <td>(päikene,)</td>\n",
       "      <td>st</td>\n",
       "      <td></td>\n",
       "      <td>sg el</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>päike</td>\n",
       "      <td>päike</td>\n",
       "      <td>(päike,)</td>\n",
       "      <td>st</td>\n",
       "      <td></td>\n",
       "      <td>sg el</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>(ja,)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>energiast</td>\n",
       "      <td>energia</td>\n",
       "      <td>energia</td>\n",
       "      <td>(energia,)</td>\n",
       "      <td>st</td>\n",
       "      <td></td>\n",
       "      <td>sg el</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>(.,)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name=morph_analysis, spans=SL[AS[Span(Eestimaal, {'clitic': '', 'ending': 'l', 'form': 'sg ad', 'lemma': 'Eestimaa', 'partofspeech': 'H', 'root': 'Eesti_maa', 'root_tokens': ('Eesti', 'maa')})],\n",
       "AS[Span(tunnevad, {'clitic': '', 'ending': 'vad', 'form': 'vad', 'lemma': 'tundma', 'partofspeech': 'V', 'root': 'tund', 'root_tokens': ('tund',)})],\n",
       "AS[Span(inimesed, {'clitic': '', 'ending': 'd', 'form': 'pl n', 'lemma': 'inimene', 'partofspeech': 'S', 'root': 'inimene', 'root_tokens': ('inimene',)})],\n",
       "AS[Span(palju, {'clitic': '', 'ending': '0', 'form': '', 'lemma': 'palju', 'partofspeech': 'D', 'root': 'palju', 'root_tokens': ('palju',)})],\n",
       "AS[Span(puudust, {'clitic': '', 'ending': 't', 'form': 'sg p', 'lemma': 'puudus', 'partofspeech': 'S', 'root': 'puudus', 'root_tokens': ('puudus',)})],\n",
       "AS[Span(päikesest, {'clitic': '', 'ending': 'st', 'form': 'sg el', 'lemma': 'päikene', 'partofspeech': 'S', 'root': 'päikene', 'root_tokens': ('päikene',)}),\n",
       "Span(päikesest, {'clitic': '', 'ending': 'st', 'form': 'sg el', 'lemma': 'päike', 'partofspeech': 'S', 'root': 'päike', 'root_tokens': ('päike',)})],\n",
       "AS[Span(ja, {'clitic': '', 'ending': '0', 'form': '', 'lemma': 'ja', 'partofspeech': 'J', 'root': 'ja', 'root_tokens': ('ja',)})],\n",
       "AS[Span(energiast, {'clitic': '', 'ending': 'st', 'form': 'sg el', 'lemma': 'energia', 'partofspeech': 'S', 'root': 'energia', 'root_tokens': ('energia',)})],\n",
       "AS[Span(., {'clitic': '', 'ending': '', 'form': '', 'lemma': '.', 'partofspeech': 'Z', 'root': '.', 'root_tokens': ('.',)})]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "text = Text('Eestimaal tunnevad inimesed palju puudust päikesest ja energiast.').tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `PhraseTagger` to tag sequences of lemmas on that text. The lemma sequences are read from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Vocabulary</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>_phrase_</th>\n",
       "      <th>value</th>\n",
       "      <th>_priority_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>('päike',)</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('tundma', 'inimene')</td>\n",
       "      <td>TI_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>TI_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('tundma', 'inimene', 'palju')</td>\n",
       "      <td>TIP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Vocabulary(key='_phrase_', len=3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import Vocabulary\n",
    "\n",
    "vocabulary_file = 'phrase_vocabulary.csv'\n",
    "Vocabulary(vocabulary=vocabulary_file, key='_phrase_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Tags phrases on a given layer. Creates an enveloping layer.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>PhraseTagger</td>\n",
       "      <td>phrases</td>\n",
       "      <td>['value', '_priority_']</td>\n",
       "      <td>['morph_analysis']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_attribute</th>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_validator</th>\n",
       "      <td>&lt;function estnltk.taggers.dict_taggers.phrase_tagger.default_validator&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validator_attribute</th>\n",
       "      <td>_validator_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conflict_resolving_strategy</th>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>priority_attribute</th>\n",
       "      <td>_priority_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ambiguous</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "PhraseTagger(input_layers=['morph_analysis'], output_layer=phrases, output_attributes=['value', '_priority_'], input_attribute=lemma, global_validator=<function estnltk.taggers.dict_taggers.phrase_tagger.default_validator>, validator_attribute=_validator_, conflict_resolving_strategy=ALL, priority_attribute=_priority_, ambiguous=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import PhraseTagger\n",
    "\n",
    "tagger = PhraseTagger(output_layer='phrases',\n",
    "                      input_layer='morph_analysis',\n",
    "                      input_attribute='lemma',\n",
    "                      vocabulary=vocabulary_file,\n",
    "                      output_attributes=['value', '_priority_'],\n",
    "                      conflict_resolving_strategy='ALL',\n",
    "                      priority_attribute='_priority_',\n",
    "                      ambiguous = True)\n",
    "tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary parsed into a dict looks like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Vocabulary</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>_phrase_</th>\n",
       "      <th>value</th>\n",
       "      <th>_priority_</th>\n",
       "      <th>_validator_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>('päike',)</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function estnltk.taggers.dict_taggers.phrase_tagger.default_validator&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('tundma', 'inimene')</td>\n",
       "      <td>TI_1</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function estnltk.taggers.dict_taggers.phrase_tagger.default_validator&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>TI_2</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function estnltk.taggers.dict_taggers.phrase_tagger.default_validator&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('tundma', 'inimene', 'palju')</td>\n",
       "      <td>TIP</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function estnltk.taggers.dict_taggers.phrase_tagger.default_validator&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Vocabulary(key='_phrase_', len=3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger._vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulari can be used to initialize the tagger in form of dict as well as in form of file name.\n",
    "\n",
    "So single lemma 'päike' is tagged, sequencial lemmas 'tundma', 'inimene' are tagged twice since the vocabulary contains two interpretations for that phrase and also sequence of lemmas 'tundma', 'inimene', 'palju' is tagged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-dff57e48545c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphrases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dage/Desktop/estnltk/estnltk/taggers/tagger.py\u001b[0m in \u001b[0;36mtag\u001b[0;34m(self, text, status)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mstore\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0mcreation\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \"\"\"\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dage/Desktop/estnltk/estnltk/taggers/tagger.py\u001b[0m in \u001b[0;36mmake_layer\u001b[0;34m(self, raw_text, layers, status)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'make_layer must return Layer'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'incorrect layer name: {} != {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dage/Desktop/estnltk/estnltk/taggers/dict_taggers/phrase_tagger.py\u001b[0m in \u001b[0;36m_make_layer\u001b[0;34m(self, raw_text, layers, status)\u001b[0m\n\u001b[1;32m    106\u001b[0m                                             \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_attributes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                                                 \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                                             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_span\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dage/Desktop/estnltk/estnltk/layer/layer.py\u001b[0m in \u001b[0;36madd_span\u001b[0;34m(self, span)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_span\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspan\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSpan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnvelopingSpan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSpan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_frozen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"can't add spans to frozen layer\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_span\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_attributes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_attributes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dage/Desktop/estnltk/estnltk/layer/layer.py\u001b[0m in \u001b[0;36madd_span\u001b[0;34m(self, span)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_span\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspan\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSpan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnvelopingSpan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSpan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# the assumption is that this method is called by Layer.add_span\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mEnvelopingSpan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mspan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_equivalence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tagger.tag(text)\n",
    "text.phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the spans are kept by conflict resolving because the priorities are all equal."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:estnltk141]",
   "language": "python",
   "name": "conda-env-estnltk141-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
