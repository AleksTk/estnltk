{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphological analysis with premorph and postmorph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from estnltk.text import Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premorph and postmorph are tools to improve the morphological analysis given by vabamorf. Premorph normalizes the input before giving it to vabamorf, postmorph normalizes the output of vabamorf. By default, premorph and postmorph are both executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take a sentence that contains an unnecessary hyphen and an incorrectly declined number.\n",
    "t = Text('Tiit müüs lil-li 10e krooniga.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(text=\"Tiit müüs lil-li 10e krooniga.\")"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(text=\"Tiit müüs lil-li 10e krooniga.\")"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And let's tag an unknown layer (???) on the sentence. Cannot see that anything happened\n",
    "t.tag_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SL[SL[Span(Tiit, {'ending': '0', 'root_tokens': ['Tiit'], 'root': 'Tiit', 'lemma': 'Tiit', 'clitic': '', 'partofspeech': 'H', 'form': 'sg n'})],\n",
       "SL[Span(müüs, {'ending': 's', 'root_tokens': ['müü'], 'root': 'müü', 'lemma': 'müüma', 'clitic': '', 'partofspeech': 'V', 'form': 's'})],\n",
       "SL[Span(lil-li, {'ending': 'i', 'root_tokens': ['lill'], 'root': 'lill', 'lemma': 'lill', 'clitic': '', 'partofspeech': 'S', 'form': 'pl p'})],\n",
       "SL[Span(10e, {'ending': 'ile', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl all'}),\n",
       "Span(10e, {'ending': 'tele', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl all'}),\n",
       "Span(10e, {'ending': 'te', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl g'}),\n",
       "Span(10e, {'ending': 'isse', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl ill'}),\n",
       "Span(10e, {'ending': 'tesse', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl ill'}),\n",
       "Span(10e, {'ending': 'le', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'sg all'}),\n",
       "Span(10e, {'ending': '0', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'sg g'}),\n",
       "Span(10e, {'ending': 'sse', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'sg ill'}),\n",
       "Span(10e, {'ending': 'ile', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl all'}),\n",
       "Span(10e, {'ending': 'tele', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl all'}),\n",
       "Span(10e, {'ending': 'te', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl g'}),\n",
       "Span(10e, {'ending': 'isse', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl ill'}),\n",
       "Span(10e, {'ending': 'tesse', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl ill'}),\n",
       "Span(10e, {'ending': 'le', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'sg all'}),\n",
       "Span(10e, {'ending': 'sse', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'sg ill'})],\n",
       "SL[Span(krooniga, {'ending': 'ga', 'root_tokens': ['kroon'], 'root': 'kroon', 'lemma': 'kroon', 'clitic': '', 'partofspeech': 'S', 'form': 'sg kom'})],\n",
       "SL[Span(., {'ending': '', 'root_tokens': ['.'], 'root': '.', 'lemma': '.', 'clitic': '', 'partofspeech': 'Z', 'form': ''})]]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But now we can ask for morphological analysis of the sentence\n",
    "t.morf_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the hyphen was removed and the correct form of the word \"lilli\" was found. For 10e, all the forms of 10 that end with an 'e' are given out. (But this is not the desired behaviour...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Can we decide whether we want disambiguation and guessing? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous code actually uses WordNormalizingTagger, VabamorfTagger and VabamordCorrectionRewriter tools. So, we can write it out as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the taggers and rewriter\n",
    "from estnltk.taggers.premorph.premorf import WordNormalizingTagger\n",
    "from estnltk.taggers.morf import VabamorfTagger\n",
    "from estnltk.rewriting.postmorph.vabamorf_corrector import VabamorfCorrectionRewriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An instance of VabamorfCorrectionRewriter is created that [does something and replaces something...]. This is the rewriter that is used for postmorph by default.\n",
    "In our example, it processes the 10e token.\n",
    "If we want, we can write our own rewriter and use that instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an instance of VabamorfCorrectionRewriter \n",
    "vabamorf_corrector = VabamorfCorrectionRewriter(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's take the same sentence as previously\n",
    "t = Text('Tiit müüs lil-li 10e krooniga.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(text=\"Tiit müüs lil-li 10e krooniga.\")"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And tag the layer 'words' on it. Cannot see that anything happened\n",
    "t.tag_layer(['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SL[Span(Tiit, {}),\n",
       "Span(müüs, {}),\n",
       "Span(lil-li, {}),\n",
       "Span(10e, {}),\n",
       "Span(krooniga, {}),\n",
       "Span(., {})]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But now we can ask for the words layer\n",
    "t.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can normalize the sentence with WordNormalizingTagger that takes care of the unnecessary hypens in words and [maybe sth else?]. In our example, it normalizes the word \"lilli\". It can be replaced with our own tagger if we decide to write one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(text=\"Tiit müüs lil-li 10e krooniga.\")"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the sentence with WordNormalizingTagger\n",
    "WordNormalizingTagger().tag(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SL[Span(lil-li, {'normal': 'lilli'})]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And we can see the word that was changed\n",
    "t.normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the VabamorfTagger on the normalized layer received from WordNormalizingTagger and ask for the created VabamorfCorrectionRewriter to be used after vabamorf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(text=\"Tiit müüs lil-li 10e krooniga.\")"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tag the text with VabamorfTagger using default premorph and postmorph\n",
    "VabamorfTagger(premorf_layer='normalized', postmorph_rewriter=vabamorf_corrector).tag(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SL[SL[Span(Tiit, {'ending': '0', 'root_tokens': ['Tiit'], 'root': 'Tiit', 'lemma': 'Tiit', 'clitic': '', 'partofspeech': 'H', 'form': 'sg n'})],\n",
       "SL[Span(müüs, {'ending': 's', 'root_tokens': ['müü'], 'root': 'müü', 'lemma': 'müüma', 'clitic': '', 'partofspeech': 'V', 'form': 's'})],\n",
       "SL[Span(lil-li, {'ending': 'i', 'root_tokens': ['lill'], 'root': 'lill', 'lemma': 'lill', 'clitic': '', 'partofspeech': 'S', 'form': 'pl p'})],\n",
       "SL[Span(10e, {'ending': 'ile', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl all'}),\n",
       "Span(10e, {'ending': 'tele', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl all'}),\n",
       "Span(10e, {'ending': 'te', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl g'}),\n",
       "Span(10e, {'ending': 'isse', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl ill'}),\n",
       "Span(10e, {'ending': 'tesse', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl ill'}),\n",
       "Span(10e, {'ending': 'le', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'sg all'}),\n",
       "Span(10e, {'ending': '0', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'sg g'}),\n",
       "Span(10e, {'ending': 'sse', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'sg ill'}),\n",
       "Span(10e, {'ending': 'ile', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl all'}),\n",
       "Span(10e, {'ending': 'tele', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl all'}),\n",
       "Span(10e, {'ending': 'te', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl g'}),\n",
       "Span(10e, {'ending': 'isse', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl ill'}),\n",
       "Span(10e, {'ending': 'tesse', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl ill'}),\n",
       "Span(10e, {'ending': 'le', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'sg all'}),\n",
       "Span(10e, {'ending': 'sse', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'sg ill'})],\n",
       "SL[Span(krooniga, {'ending': 'ga', 'root_tokens': ['kroon'], 'root': 'kroon', 'lemma': 'kroon', 'clitic': '', 'partofspeech': 'S', 'form': 'sg kom'})],\n",
       "SL[Span(., {'ending': '', 'root_tokens': ['.'], 'root': '.', 'lemma': '.', 'clitic': '', 'partofspeech': 'Z', 'form': ''})]]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The same output is received as in the first example\n",
    "t.morf_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As mentioned, we can customize premorph or postmorph.\n",
    "\n",
    "To turn off postmorph for the same example, we need to set postmorph_rewriter to None:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = Text('Tiit müüs lil-li 10e krooniga.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(text=\"Tiit müüs lil-li 10e krooniga.\")"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.tag_layer(['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(text=\"Tiit müüs lil-li 10e krooniga.\")"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordNormalizingTagger().tag(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(text=\"Tiit müüs lil-li 10e krooniga.\")"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# postmorph_rewriter = None says that we don't want to apply the default rewriter\n",
    "VabamorfTagger(premorf_layer='normalized', postmorph_rewriter=None).tag(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SL[SL[Span(Tiit, {'ending': '0', 'root_tokens': ['Tiit'], 'root': 'Tiit', 'lemma': 'Tiit', 'clitic': '', 'partofspeech': 'H', 'form': 'sg n'})],\n",
       "SL[Span(müüs, {'ending': 's', 'root_tokens': ['müü'], 'root': 'müü', 'lemma': 'müüma', 'clitic': '', 'partofspeech': 'V', 'form': 's'})],\n",
       "SL[Span(lil-li, {'ending': 'i', 'root_tokens': ['lill'], 'root': 'lill', 'lemma': 'lill', 'clitic': '', 'partofspeech': 'S', 'form': 'pl p'})],\n",
       "SL[Span(10e, {'ending': '0', 'root_tokens': ['10e'], 'root': '10e', 'lemma': '10e', 'clitic': '', 'partofspeech': 'Y', 'form': '?'})],\n",
       "SL[Span(krooniga, {'ending': 'ga', 'root_tokens': ['kroon'], 'root': 'kroon', 'lemma': 'kroon', 'clitic': '', 'partofspeech': 'S', 'form': 'sg kom'})],\n",
       "SL[Span(., {'ending': '', 'root_tokens': ['.'], 'root': '.', 'lemma': '.', 'clitic': '', 'partofspeech': 'Z', 'form': ''})]]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.morf_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we got only one analysis for the token '10e' which, unfortunately, is not correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also turn off premorph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = Text('Tiit müüs lil-li 10e krooniga.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(text=\"Tiit müüs lil-li 10e krooniga.\")"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.tag_layer(['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(text=\"Tiit müüs lil-li 10e krooniga.\")"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# premorph_layer = None says that we don't want to apply the default rewriter\n",
    "VabamorfTagger(premorf_layer=None, postmorph_rewriter=vabamorf_corrector).tag(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SL[SL[Span(Tiit, {'ending': '0', 'root_tokens': ['Tiit'], 'root': 'Tiit', 'lemma': 'Tiit', 'clitic': '', 'partofspeech': 'H', 'form': 'sg n'})],\n",
       "SL[Span(müüs, {'ending': 's', 'root_tokens': ['müü'], 'root': 'müü', 'lemma': 'müüma', 'clitic': '', 'partofspeech': 'V', 'form': 's'})],\n",
       "SL[Span(lil-li, {'ending': '0', 'root_tokens': ['lil', 'li'], 'root': 'lil-li', 'lemma': 'lil-li', 'clitic': '', 'partofspeech': 'Y', 'form': '?'})],\n",
       "SL[Span(10e, {'ending': 'ile', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl all'}),\n",
       "Span(10e, {'ending': 'tele', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl all'}),\n",
       "Span(10e, {'ending': 'te', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl g'}),\n",
       "Span(10e, {'ending': 'isse', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl ill'}),\n",
       "Span(10e, {'ending': 'tesse', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl ill'}),\n",
       "Span(10e, {'ending': 'le', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'sg all'}),\n",
       "Span(10e, {'ending': '0', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'sg g'}),\n",
       "Span(10e, {'ending': 'sse', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'sg ill'}),\n",
       "Span(10e, {'ending': 'ile', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl all'}),\n",
       "Span(10e, {'ending': 'tele', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl all'}),\n",
       "Span(10e, {'ending': 'te', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl g'}),\n",
       "Span(10e, {'ending': 'isse', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl ill'}),\n",
       "Span(10e, {'ending': 'tesse', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl ill'}),\n",
       "Span(10e, {'ending': 'le', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'sg all'}),\n",
       "Span(10e, {'ending': 'sse', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'sg ill'})],\n",
       "SL[Span(krooniga, {'ending': 'ga', 'root_tokens': ['kroon'], 'root': 'kroon', 'lemma': 'kroon', 'clitic': '', 'partofspeech': 'S', 'form': 'sg kom'})],\n",
       "SL[Span(., {'ending': '', 'root_tokens': ['.'], 'root': '.', 'lemma': '.', 'clitic': '', 'partofspeech': 'Z', 'form': ''})]]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.morf_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(text=\"Tiit müüs lil-li 10e krooniga.\")"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the word \"lil-li\" was not normalized and therefore didn't receive the correct analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Can't we switch off premorph and postmorph some easier way?\n",
    "# Somehow without explicitly creating the VabamorfTagger?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the `morf_analysis` layer to create a `corrected_morph` layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What is the purpose of this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a text object.\n",
    "2. Tag the `normalized` layer (and also the `words` layer  #this happens somehow magically by tagging the 'normalized' layer?).\n",
    "3. Create a layer `_morph` that contains the data from the layers `morf_analysis` and `normalized`.\n",
    "5. Rewrite the `_morph` layer and get the `corrected_morph` layer as a result.\n",
    "6. Attach the `corrected_morph` layer to the text object.\n",
    "\n",
    "Now `text.corrected_morph` is the same as `t.morf_analysis` in the first example where premorph and postmorph are executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the necessary stuff\n",
    "from estnltk.text import Span, Layer\n",
    "from estnltk.rewriting.postmorph.vabamorf_corrector import VabamorfCorrectionRewriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(text=\"Tiit müüs lil-li 10e krooniga.\")"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = Text('Tiit müüs lil-li 10e krooniga.')\n",
    "text.tag_layer(['normalized'])\n",
    "VabamorfTagger(premorf_layer='normalized', postmorph_rewriter=None).tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the attributes of the morf_analysis layer? Why do I need to specify them here? \n",
    "morph_attributes = ['form', 'root_tokens', 'clitic', 'partofspeech', 'ending', 'root', 'lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attributes = morph_attributes + ['word_normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "_morph = Layer(name='words',\n",
    "               parent='words',\n",
    "               ambiguous=True,\n",
    "               attributes=attributes\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word, analyses in zip(text.words, text.morf_analysis):\n",
    "    for analysis in analyses:\n",
    "        span = _morph.add_span(Span(parent=word))\n",
    "        for attr in morph_attributes:\n",
    "            setattr(span, attr, getattr(analysis, attr))\n",
    "        setattr(span, 'word_normal', word.normal or word.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "postmorph_rewriter = VabamorfCorrectionRewriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corrected_morph = _morph.rewrite(source_attributes=attributes,\n",
    "                                 target_attributes=morph_attributes, \n",
    "                                 rules=postmorph_rewriter,\n",
    "                                 name='corrected_morph',\n",
    "                                 ambiguous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text['corrected_morph'] = corrected_morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SL[SL[Span(Tiit, {'ending': '0', 'root_tokens': ['Tiit'], 'root': 'Tiit', 'lemma': 'Tiit', 'clitic': '', 'partofspeech': 'H', 'form': 'sg n'})],\n",
       "SL[Span(müüs, {'ending': 's', 'root_tokens': ['müü'], 'root': 'müü', 'lemma': 'müüma', 'clitic': '', 'partofspeech': 'V', 'form': 's'})],\n",
       "SL[Span(lil-li, {'ending': 'i', 'root_tokens': ['lill'], 'root': 'lill', 'lemma': 'lill', 'clitic': '', 'partofspeech': 'S', 'form': 'pl p'})],\n",
       "SL[Span(10e, {'ending': 'ile', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl all'}),\n",
       "Span(10e, {'ending': 'tele', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl all'}),\n",
       "Span(10e, {'ending': 'te', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl g'}),\n",
       "Span(10e, {'ending': 'isse', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl ill'}),\n",
       "Span(10e, {'ending': 'tesse', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'pl ill'}),\n",
       "Span(10e, {'ending': 'le', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'sg all'}),\n",
       "Span(10e, {'ending': '0', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'sg g'}),\n",
       "Span(10e, {'ending': 'sse', 'root_tokens': ['10'], 'root': '10', 'lemma': '10', 'clitic': '', 'partofspeech': 'N', 'form': 'sg ill'}),\n",
       "Span(10e, {'ending': 'ile', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl all'}),\n",
       "Span(10e, {'ending': 'tele', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl all'}),\n",
       "Span(10e, {'ending': 'te', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl g'}),\n",
       "Span(10e, {'ending': 'isse', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl ill'}),\n",
       "Span(10e, {'ending': 'tesse', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'pl ill'}),\n",
       "Span(10e, {'ending': 'le', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'sg all'}),\n",
       "Span(10e, {'ending': 'sse', 'root_tokens': ['10.'], 'root': '10.', 'lemma': '10.', 'clitic': '', 'partofspeech': 'O', 'form': 'sg ill'})],\n",
       "SL[Span(krooniga, {'ending': 'ga', 'root_tokens': ['kroon'], 'root': 'kroon', 'lemma': 'kroon', 'clitic': '', 'partofspeech': 'S', 'form': 'sg kom'})],\n",
       "SL[Span(., {'ending': '', 'root_tokens': ['.'], 'root': '.', 'lemma': '.', 'clitic': '', 'partofspeech': 'Z', 'form': ''})]]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.corrected_morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(text=\"Tiit müüs lil-li 10e krooniga.\")"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = Text('Tiit müüs lil-li 10e krooniga.')\n",
    "text1.tag_layer(['normalized'])\n",
    "VabamorfTagger(premorf_layer='normalized', postmorph_rewriter=postmorph_rewriter).tag(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(text1.morf_analysis) == str(text.corrected_morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the end, we have the same output as from the first example but with a different name?\n",
    "# No clue why we did this."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:estnltk141]",
   "language": "python",
   "name": "conda-env-estnltk141-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
