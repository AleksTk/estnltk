{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Storing of `Text` objects in a PostgreSQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to store and query EstNLTK `Text` objects in a PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text, logger\n",
    "from estnltk.taggers import VabamorfTagger, WordTagger\n",
    "from estnltk.storage.postgres import PostgresStorage, create_schema, delete_schema\n",
    "from estnltk.storage.postgres import JsonbTextQuery, JsonbLayerQuery, WhereClause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:storage.py:41: connecting to host: 'localhost', port: '5432', dbname: 'test_db', user: 'pault'\n",
      "INFO:storage.py:57: schema: 'my_schema', temporary: False, role: 'pault'\n"
     ]
    }
   ],
   "source": [
    "storage = PostgresStorage(host=None,\n",
    "                          port=None,\n",
    "                          dbname='test_db',\n",
    "                          user=None,\n",
    "                          password=None,\n",
    "                          pgpass_file='~/.pgpass',\n",
    "                          schema='my_schema',\n",
    "                          role=None,\n",
    "                          temporary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any of the parameters `host`, `port`, `dbname`, `user` or `password` is `None` then the missing values are searced from the `pgpass_file`. The first line of the file that matches the given arguments is used to connect to an existing PostgreSQL database.\n",
    "\n",
    "File line format:\n",
    "\n",
    "    host:port:dbname:user:password\n",
    " \n",
    "Example file contents:\n",
    "\n",
    "    # host:port:dbname:user:password\n",
    "    localhost:5432:test_db:username:password\n",
    "    example.com:5432:*:exampleuser:kj3dno34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create schema\n",
    "\n",
    "Probably the schema is already set up in the database. If not and you have enough privileges you can create one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_schema(storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create collections\n",
    "\n",
    "Now new collections can be created and displayed. Collection stores `Text` objects in the database and provides a read/write API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:106: new empty collection 'my_first_collection' created\n",
      "INFO:collection.py:106: new empty collection 'my_second_collection' created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PostgresStorage</b><br/>\n",
       "host=localhost port=5432 dbname=test_db user=pault schema=my_schema<br/>temporary=False<br/>\n",
       "collection count: 2\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total_size</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collection</th>\n",
       "      <th>layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>my_first_collection</th>\n",
       "      <th></th>\n",
       "      <td>32 kB</td>\n",
       "      <td>first demo collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_second_collection</th>\n",
       "      <th></th>\n",
       "      <td>32 kB</td>\n",
       "      <td>second demo collection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.storage.PostgresStorage at 0x7f23e8022b00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage['my_first_collection'].create('first demo collection')\n",
    "storage['my_second_collection'].create('second demo collection')\n",
    "storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection names as a list of strings is also available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_first_collection', 'my_second_collection']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage.collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del storage['my_first_collection']\n",
    "# or\n",
    "storage['my_second_collection'].delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the storage is empty again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>PostgresStorage</b><br/>\n",
       "host=localhost port=5432 dbname=test_db user=pault schema=my_schema<br/>temporary=False<br/>\n",
       "collection count: 0\n",
       "<br/>This storage has no collections."
      ],
      "text/plain": [
       "<estnltk.storage.postgres.storage.PostgresStorage at 0x7f23e8022b00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add texts\n",
    "\n",
    "Let's create a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:106: new empty collection 'my_collection' created\n"
     ]
    }
   ],
   "source": [
    "collection = storage[\"my_collection\"].create(description='demo collection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and add some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:325: inserted 1 texts into the collection 'my_collection'\n"
     ]
    }
   ],
   "source": [
    "with collection.insert() as collection_insert:\n",
    "    text1 = Text('Ööbik laulab.').tag_layer(['morph_analysis'])\n",
    "    collection_insert(text1)\n",
    "\n",
    "    text2 = Text('Öökull ei laula.').tag_layer(['morph_analysis'])\n",
    "    key2 = collection_insert(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All inserted `Text` objects must have the same layers.\n",
    "\n",
    "You can see what's inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> my_collection<br/><b>storage:</b> PostgresStorage(host=localhost port=5432 dbname=test_db user=pault schema=my_schema temporary=False)<br/><b>count objects:</b> 2<br/><b>Metadata</b><br/>This collection has no metadata.<br/><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>_base</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morph_analysis</th>\n",
       "      <td>attached</td>\n",
       "      <td>(lemma, root, root_tokens, ending, clitic, for...</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>sentences</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x7f23e8022470>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layers inserted with the `Text` objects are stored in the same database table with the `Text` object and are called **attached** layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create layers\n",
    "\n",
    "The `create_layer` method creates a new layer for every `Text` object in the collection. These layers are stored in separate database files and are called **detached** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:925: collection: 'my_collection'\n",
      "INFO:collection.py:944: preparing to create a new layer: 'detached_morph_1'\n",
      "INFO:collection.py:977: inserting data into the 'detached_morph_1' layer table\n",
      "INFO:collection.py:1012: layer created: 'detached_morph_1'\n",
      "INFO:collection.py:925: collection: 'my_collection'\n",
      "INFO:collection.py:944: preparing to create a new layer: 'detached_morph_2'\n",
      "INFO:collection.py:977: inserting data into the 'detached_morph_2' layer table\n",
      "INFO:collection.py:1012: layer created: 'detached_morph_2'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> my_collection<br/><b>storage:</b> PostgresStorage(host=localhost port=5432 dbname=test_db user=pault schema=my_schema temporary=False)<br/><b>count objects:</b> 2<br/><b>Metadata</b><br/>This collection has no metadata.<br/><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>_base</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detached_morph_1</th>\n",
       "      <td>detached</td>\n",
       "      <td>(lemma, root, root_tokens, ending, clitic, for...</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detached_morph_2</th>\n",
       "      <td>detached</td>\n",
       "      <td>(lemma, root, root_tokens, ending, clitic, for...</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morph_analysis</th>\n",
       "      <td>attached</td>\n",
       "      <td>(lemma, root, root_tokens, ending, clitic, for...</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>sentences</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x7f23e8022470>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1 = 'detached_morph_1'\n",
    "layer_2 = 'detached_morph_2'\n",
    "\n",
    "tagger = VabamorfTagger(disambiguate=False, layer_name=layer_1)\n",
    "collection.create_layer(tagger=tagger)\n",
    "\n",
    "tagger = VabamorfTagger(disambiguate=False, layer_name=layer_2)\n",
    "collection.create_layer(tagger=tagger)\n",
    "\n",
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of `Text` objects in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't list the collection elements if the collction is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(text='Ööbik laulab.'), Text(text='Öökull ei laula.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collection yields `Text` objects with selected layers. The selected layers are by default the attached layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tokens', 'compound_tokens', 'words', 'sentences', 'morph_analysis']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.selected_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dependencies are included automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['words', 'detached_morph_1']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.selected_layers = [layer_1]\n",
    "collection.selected_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexes start fron `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ööbik laulab.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>detached_morph_1</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ööbik laulab.')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for a particular entry by key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, Text(text='Öökull ei laula.'))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(collection.select(keys=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Text` objects can be searced by the layer attribute values.\n",
    "\n",
    "Use `JsonbTextQuery` to search the texts by the attribute values in the attached layers and `JsonbLayerQuery` to search by the detached layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Öökull ei laula.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Öökull ei laula.')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.select_by_key(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "q = JsonbTextQuery('morph_analysis', lemma='laulma')\n",
    "for key, txt in collection.select(query=q):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "q = {layer_1: JsonbLayerQuery(layer_name=layer_1, lemma='laulma')}\n",
    "\n",
    "for key, text in collection.select(layer_query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search using multiple layer attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n"
     ]
    }
   ],
   "source": [
    "q = JsonbTextQuery('morph_analysis', lemma='laulma', form='b')\n",
    "\n",
    "for key, txt in collection.select(query=q):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n"
     ]
    }
   ],
   "source": [
    "q = {layer_1: JsonbLayerQuery(layer_name=layer_1, lemma='laulma', form='b')}\n",
    "\n",
    "for key, text in collection.select(layer_query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search using \"OR\" query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "q = JsonbTextQuery('morph_analysis', lemma='ööbik') | \\\n",
    "    JsonbTextQuery('morph_analysis', lemma='öökull')\n",
    "\n",
    "for key, txt in collection.select(query=q):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "q = {layer_1: JsonbLayerQuery(layer_name=layer_1, lemma='ööbik') | \n",
    "              JsonbLayerQuery(layer_name=layer_1, lemma='öökull')}\n",
    "\n",
    "for key, text in collection.select(layer_query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search using \"AND\" query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = JsonbTextQuery('morph_analysis', lemma='ööbik') & \\\n",
    "    JsonbTextQuery('morph_analysis', lemma='öökull')\n",
    "for key, txt in collection.select(query=q):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = {layer_1: JsonbLayerQuery(layer_name=layer_1, lemma='ööbik') & \n",
    "              JsonbLayerQuery(layer_name=layer_1, lemma='öökull')}\n",
    "\n",
    "for key, text in collection.select(layer_query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search using a composite query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "q = (JsonbTextQuery('morph_analysis', lemma='ööbik') | JsonbTextQuery('morph_analysis', lemma='öökull')) & \\\n",
    "     JsonbTextQuery('morph_analysis', lemma='laulma')\n",
    "for key, txt in collection.select(query=q):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "q = {layer_1: (JsonbLayerQuery(layer_name=layer_1, lemma='ööbik') | \n",
    "               JsonbLayerQuery(layer_name=layer_1, lemma='öökull')) & \n",
    "              JsonbLayerQuery(layer_name=layer_1, lemma='laulma')}\n",
    "\n",
    "for key, text in collection.select(layer_query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or use a convenience method `find_fingerprint`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "q = {\"layer\": \"morph_analysis\",\n",
    "     \"ambiguous\": True,\n",
    "     \"field\": \"lemma\",\n",
    "     \"query\": [{'ööbik', 'laulma'}, {'öökull', 'laulma'}] # (ööbik AND laulma) OR (öökull AND laulma)\n",
    "     }\n",
    "\n",
    "for key, txt in collection.find_fingerprint(query=q, order_by_key=True):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "for key, txt in collection.find_fingerprint(\n",
    "                    query={\n",
    "                        \"layer\": \"morph_analysis\",\n",
    "                        \"ambiguous\": True,\n",
    "                        \"field\": \"lemma\",\n",
    "                        \"query\": ['öökull', 'laulma'] # öökull OR laulma\n",
    "                    },\n",
    "                    order_by_key=True):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "for key, txt in collection.find_fingerprint(\n",
    "                    query={\n",
    "                        \"layer\": \"morph_analysis\",\n",
    "                        \"ambiguous\": True,\n",
    "                        \"field\": \"lemma\",\n",
    "                        \"query\": [{'öökull', 'laulma'}] # öökull AND laulma\n",
    "                    },\n",
    "                    order_by_key=True):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "for key, text in collection.find_fingerprint(layer_query={\n",
    "            layer_1: {\n",
    "                \"field\": \"lemma\",\n",
    "                \"query\": [\"ööbik\", \"öökull\"],\n",
    "                \"ambiguous\": True\n",
    "            },\n",
    "            layer_2: {\n",
    "                \"field\": \"lemma\",\n",
    "                \"query\": [\"laulma\"],\n",
    "                \"ambiguous\": True\n",
    "            }}):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search over multiple layers using `JsonbLayerQuery`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "for key, text in collection.select(layer_query={\n",
    "        layer_1: JsonbLayerQuery(layer_name=layer_1, lemma='ööbik') | \\\n",
    "                 JsonbLayerQuery(layer_name=layer_1, lemma='öökull'),\n",
    "        layer_2: JsonbLayerQuery(layer_name=layer_2, lemma='laulma')\n",
    "        }):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:106: new empty collection 'collection_with_layers' created\n",
      "INFO:collection.py:325: inserted 1 texts into the collection 'collection_with_layers'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> collection_with_layers<br/><b>storage:</b> PostgresStorage(host=localhost port=5432 dbname=test_db user=pault schema=my_schema temporary=False)<br/><b>count objects:</b> 2<br/><b>Metadata</b><br/>This collection has no metadata.<br/><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>_base</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>sentences</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x7f23e772eef0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = storage.get_collection('collection_with_layers')\n",
    "collection.create()\n",
    "\n",
    "with collection.insert() as collection_insert:\n",
    "    collection_insert(Text('See on esimene lause.').tag_layer([\"sentences\"]))\n",
    "    collection_insert(Text('See on teine lause.').tag_layer([\"sentences\"]))\n",
    "\n",
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngram index enables to index ngrams in layer attributes.\n",
    "For example, a bigram index on an attribute with values `['see', 'on', 'esimene', 'lause']` will contain pairs *'see-on'*, *'on-esimene'*, *'esimene-lause'*.\n",
    "Indices of a higher order are also supported.\n",
    "\n",
    "To build an ngram index, provide an argument *ngram_index* when creating a new layer.\n",
    "The following code creates a bi-gram index on an attribute *lemma* for a newly created layer *indexed_layer*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:925: collection: 'collection_with_layers'\n",
      "INFO:collection.py:944: preparing to create a new layer: 'indexed_layer'\n",
      "INFO:collection.py:977: inserting data into the 'indexed_layer' layer table\n",
      "INFO:collection.py:1012: layer created: 'indexed_layer'\n"
     ]
    }
   ],
   "source": [
    "indexed_layer = 'indexed_layer'\n",
    "tagger = VabamorfTagger(disambiguate=False, layer_name=indexed_layer)\n",
    "\n",
    "collection.create_layer(tagger=tagger, ngram_index={\"lemma\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search an ngram index, use the `find_fingerprint` method along with `layer_ngram_query` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search entries containing lemma bigram 'see-olema':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='See on esimene lause.')\n",
      "1 Text(text='See on teine lause.')\n"
     ]
    }
   ],
   "source": [
    "q = {indexed_layer: {\n",
    "        \"lemma\": [(\"see\", \"olema\")]\n",
    "    }}\n",
    "for key, text in collection.find_fingerprint(layer_ngram_query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search 'teine-lause' OR 'olema-esimene':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='See on esimene lause.')\n",
      "1 Text(text='See on teine lause.')\n"
     ]
    }
   ],
   "source": [
    "q = {indexed_layer: {\n",
    "        \"lemma\": [(\"teine\", \"lause\"), (\"olema\", \"esimene\")]\n",
    "    }}\n",
    "for key, text in collection.find_fingerprint(layer_ngram_query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search 'see-olema' AND 'olema-esimene':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='See on esimene lause.')\n"
     ]
    }
   ],
   "source": [
    "q = {indexed_layer: {\n",
    "        \"lemma\": [[(\"see\", \"olema\"), (\"olema\", \"esimene\")]]\n",
    "    }}\n",
    "for key, text in collection.find_fingerprint(layer_ngram_query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `PgSubCollection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:106: new empty collection 'my_collection' created\n",
      "INFO:collection.py:325: inserted 2 texts into the collection 'my_collection'\n"
     ]
    }
   ],
   "source": [
    "collection = storage.get_collection('my_collection')\n",
    "collection.create()\n",
    "\n",
    "texts = ['Esimene tekst.', 'Teine tekst.', 'Kolmas tekst.']\n",
    "\n",
    "with collection.insert() as collection_insert:\n",
    "    for t in texts:\n",
    "        collection_insert(Text(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:925: collection: 'my_collection'\n",
      "INFO:collection.py:944: preparing to create a new layer: 'tokens'\n",
      "INFO:collection.py:977: inserting data into the 'tokens' layer table\n",
      "INFO:collection.py:1012: layer created: 'tokens'\n"
     ]
    }
   ],
   "source": [
    "from estnltk.taggers import TokensTagger\n",
    "\n",
    "tokens_tagger = TokensTagger()\n",
    "\n",
    "collection.create_layer(tagger=tokens_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `select` method returns a `PgSubCollection` object that provides read-only access to a subset of the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PgSubCollection(collection: 'my_collection', selected_layers=[], meta_attributes=(), progressbar=None, return_index=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.select(query=None,\n",
    "                  layer_query=None, \n",
    "                  layer_ngram_query=None,\n",
    "                  layers=None,  # Sequence[str] \n",
    "                  keys = None,  # Sequence[int] \n",
    "                  collection_meta=None,  # Sequence[str] \n",
    "                  progressbar=None,  # str\n",
    "                  missing_layer=None,  # str \n",
    "                  return_index=True  # bool\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0021b4bc51ae4202ad52ebc07885edb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, Text(text='Esimene tekst.'))\n",
      "(1, Text(text='Teine tekst.'))\n",
      "(2, Text(text='Kolmas tekst.'))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in collection.select(progressbar='notebook', return_index=True):\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get detached layer without `Text` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PgSubCollectionLayer(collection: 'my_collection', detached_layer='tokens', progressbar=None, return_index=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detached_layers = collection.select(return_index=False).detached_layer('tokens')\n",
    "detached_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "No Text object.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='tokens', attributes=(), spans=SL[Span(start=0, end=7, layer: 'tokens'),\n",
       "Span(start=8, end=13, layer: 'tokens'),\n",
       "Span(start=13, end=14, layer: 'tokens')])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(detached_layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:106: new empty collection 'collection_with_fragments' created\n",
      "INFO:collection.py:325: inserted 1 texts into the collection 'collection_with_fragments'\n",
      "INFO:collection.py:805: collection: 'collection_with_fragments'\n",
      "INFO:collection.py:861: fragmented layer created: 'fragmented_morph'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> collection_with_fragments<br/><b>storage:</b> PostgresStorage(host=localhost port=5432 dbname=test_db user=pault schema=my_schema temporary=False)<br/><b>count objects:</b> 2<br/><b>Metadata</b><br/>This collection has no metadata.<br/><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>_base</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fragmented_morph</th>\n",
       "      <td>fragmented</td>\n",
       "      <td>(lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morph_analysis</th>\n",
       "      <td>attached</td>\n",
       "      <td>(lemma, root, root_tokens, ending, clitic, form, partofspeech)</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>sentences</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x7f23e774e898>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = storage[\"collection_with_fragments\"].create(description='demo collection')\n",
    "\n",
    "with collection.insert() as collection_insert:\n",
    "    text1 = Text('Ööbik laulab.').tag_layer(['morph_analysis'])\n",
    "    collection_insert(text1)\n",
    "\n",
    "    text2 = Text('Öökull ei laula.').tag_layer(['morph_analysis'])\n",
    "    key2 = collection_insert(text2)\n",
    "\n",
    "    \n",
    "def fragmenter(layer):\n",
    "    return [layer]\n",
    "\n",
    "\n",
    "tagger = VabamorfTagger(disambiguate=False, layer_name='fragmented_morph')\n",
    "\n",
    "collection.create_fragmented_layer(tagger=tagger, fragmenter=fragmenter)\n",
    "\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:106: new empty collection 'fragment_test' created\n",
      "INFO:collection.py:325: inserted 1 texts into the collection 'fragment_test'\n",
      "INFO:collection.py:696: collection: 'fragment_test'\n",
      "INFO:collection.py:707: preparing to create a new layer: 'layer_fragment_1'\n",
      "INFO:collection.py:770: layer created: 'layer_fragment_1'\n"
     ]
    }
   ],
   "source": [
    "from estnltk.storage.postgres import select_raw, RowMapperRecord\n",
    "\n",
    "table_name = 'fragment_test'\n",
    "collection = storage.get_collection(table_name)\n",
    "collection.create()\n",
    "\n",
    "with collection.insert() as collection_insert:\n",
    "    text1 = Text('see on esimene lause').tag_layer([\"sentences\"])\n",
    "    collection_insert(text1)\n",
    "    text2 = Text('see on teine lause').tag_layer([\"sentences\"])\n",
    "    collection_insert(text2)\n",
    "\n",
    "layer_fragment_name = \"layer_fragment_1\"\n",
    "tagger = VabamorfTagger(disambiguate=False, layer_name=layer_fragment_name)\n",
    "collection.old_slow_create_layer(layer_fragment_name,\n",
    "                                 data_iterator=collection.select(layers=['sentences', 'compound_tokens']),\n",
    "                                 row_mapper=lambda row: [\n",
    "                                     RowMapperRecord(layer=tagger.tag(row[1], return_layer=True), meta=None)])\n",
    "\n",
    "fragment_name = \"fragment_1\"\n",
    "\n",
    "def row_mapper(row):\n",
    "    text_id, text, meta, detached_layers = row\n",
    "    parent_layer = detached_layers[layer_fragment_name]['layer']\n",
    "    parent_id = detached_layers[layer_fragment_name]['layer_id']\n",
    "    return [{'fragment': parent_layer, 'parent_id': parent_id},\n",
    "            {'fragment': parent_layer, 'parent_id': parent_id}]\n",
    "\n",
    "collection.create_fragment(fragment_name,\n",
    "                    data_iterator=select_raw(collection=collection,\n",
    "                                             detached_layers=[layer_fragment_name]),\n",
    "                    row_mapper=row_mapper,\n",
    "                    create_index=False,\n",
    "                    ngram_index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_schema(storage)\n",
    "storage.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
