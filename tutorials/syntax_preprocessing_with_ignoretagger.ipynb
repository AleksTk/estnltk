{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SyntaxIgnoreTagger in pre-processing for syntactic analysis\n",
    "\n",
    "Some parts of a text may be difficult to analyse syntactically. For instance, enumerations of sports results, parenthesised references and short remarks usually consist of \"very compactly packaged information\", which exhibits only little linguistic syntactic structure. So, you may want to skip the syntactic analysis on such parts of the text.\n",
    "\n",
    "In order to detect parts of text that should be ignored by the syntactic analysis, EstNLTK has a special tagger called SyntaxIgnoreTagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Tags text snippets that should be ignored during the syntactic analysis.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>layer</th>\n",
       "      <th>attributes</th>\n",
       "      <th>depends_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>SyntaxIgnoreTagger</td>\n",
       "      <td>syntax_ignore</td>\n",
       "      <td>(type,)</td>\n",
       "      <td>[words, sentences]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>allow_loose_match</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignore_brackets</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignore_consecutive_enum_ucase_num_sentences</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignore_consecutive_parenthesized_sentences</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignore_parenthesized_num</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignore_parenthesized_num_greedy</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignore_parenthesized_ref</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignore_parenthesized_short_char_sequences</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignore_parenthesized_title_words</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignore_sentences_consisting_of_numbers</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignore_sentences_starting_with_time</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignore_sentences_with_comma_separated_num_name_lists</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SyntaxIgnoreTagger(allow_loose_match=True, ignore_brackets=True, ignore_consecutive_enum_ucase_num_sentences=True, ignore_consecutive_parenthesized_sentences=True, ignore_parenthesized_num=True, ignore_parenthesized_num_greedy=True, ignore_parenthesized_ref=True, ignore_parenthesized_short_char_sequences=True, ignore_parenthesized_title_words=True, ignore_sentences_consisting_of_numbers=True, ignore_sentences_starting_with_time=True, ignore_sentences_with_comma_separated_num_name_lists=True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers.syntax_preprocessing.syntax_ignore_tagger import SyntaxIgnoreTagger\n",
    "syntax_ignore_tagger = SyntaxIgnoreTagger()\n",
    "syntax_ignore_tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SyntaxIgnoreTagger requires that 'words' and 'sentences' have been annotated in text. It uses these layers to detect snippets of text (not necessarily full sentences) which should be ignored during the syntactic analysis. Detection patterns are partly based on the patterns used in pre-processing modules of EstSyntax, available [here](https://github.com/kristiinavaik/ettenten-eeltootlus) and [here](https://github.com/EstSyntax/preprocessing-module).\n",
    "\n",
    "Similar detection patterns have been grouped together. Upon the initialization of the tagger, flags can be used to switch these groups off (by default, all flags have been switched on). In following, we will give a minute introduction on the flags, and types of ignorable text snippets the corresponding patterns aim to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patterns for detecting ignore content inside sentences\n",
    "\n",
    "#### Flag `ignore_brackets`\n",
    "\n",
    "Content inside square brackets will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>syntax_ignore</td>\n",
       "      <td>type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>[</b><b>9</b><b>:</b> <b>5</b><b>]</b></td>\n",
       "      <td>98</td>\n",
       "      <td>104</td>\n",
       "      <td>brackets_ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>[</b><b>9</b> <b>lk</b> <b>5</b><b>]</b></td>\n",
       "      <td>109</td>\n",
       "      <td>117</td>\n",
       "      <td>brackets_ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>[</b><b>7</b><b>]</b></td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>brackets_ref</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span([, {'normalized_form': None}),\n",
       "Span(9, {'normalized_form': None}),\n",
       "Span(:, {'normalized_form': None}),\n",
       "Span(5, {'normalized_form': None}),\n",
       "Span(], {'normalized_form': None})],\n",
       "SL[Span([, {'normalized_form': None}),\n",
       "Span(9, {'normalized_form': None}),\n",
       "Span(lk, {'normalized_form': None}),\n",
       "Span(5, {'normalized_form': None}),\n",
       "Span(], {'normalized_form': None})],\n",
       "SL[Span([, {'normalized_form': None}),\n",
       "Span(7, {'normalized_form': None}),\n",
       "Span(], {'normalized_form': None})]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text and preprocess\n",
    "from estnltk.text import Text\n",
    "text = Text('Nurksulgudes tuuakse materjali viitekirje järjekorranumber kirjanduse loetelus ja leheküljed , nt [9: 5] või [9 lk 5], aga internetimaterjalil lihtsalt viitekirje, nt [7]')\n",
    "text.tag_layer(['words', 'sentences'])\n",
    "\n",
    "# Apply syntax_ignore_tagger\n",
    "syntax_ignore_tagger = SyntaxIgnoreTagger(ignore_brackets=True)\n",
    "syntax_ignore_tagger.tag(text)\n",
    "\n",
    "# Examine results\n",
    "text.syntax_ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flag `ignore_parenthesized_ref`\n",
    "\n",
    "Parenthesized content which looks like a reference (e.g. contains titlecased words, and date information) will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>syntax_ignore</td>\n",
       "      <td>type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>(</b><b>Tuum</b> <b>2012</b><b>)</b></td>\n",
       "      <td>47</td>\n",
       "      <td>58</td>\n",
       "      <td>parentheses_ref_year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>(</b><b>Varrak</b> <b>2012</b><b>)</b></td>\n",
       "      <td>97</td>\n",
       "      <td>110</td>\n",
       "      <td>parentheses_ref_year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>(</b><b>Priit</b> <b>Pullerits</b> <b>«</b><b>Džiibi</b> <b>kaitseks</b><b>»,</b> <b>PM</b> <b>30.07.2010</b><b>)</b></td>\n",
       "      <td>174</td>\n",
       "      <td>224</td>\n",
       "      <td>parentheses_ref_year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span((, {'normalized_form': None}),\n",
       "Span(Tuum, {'normalized_form': None}),\n",
       "Span(2012, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None})],\n",
       "SL[Span((, {'normalized_form': None}),\n",
       "Span(Varrak, {'normalized_form': None}),\n",
       "Span(2012, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None})],\n",
       "SL[Span((, {'normalized_form': None}),\n",
       "Span(Priit, {'normalized_form': None}),\n",
       "Span(Pullerits, {'normalized_form': None}),\n",
       "Span(«, {'normalized_form': None}),\n",
       "Span(Džiibi, {'normalized_form': None}),\n",
       "Span(kaitseks, {'normalized_form': None}),\n",
       "Span(»,, {'normalized_form': None}),\n",
       "Span(PM, {'normalized_form': None}),\n",
       "Span(30.07.2010, {'normalized_form': '30.07.2010'}),\n",
       "Span(), {'normalized_form': None})]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text and preprocess\n",
    "from estnltk.text import Text\n",
    "text = Text('Tutvustamisele tulevad Jan Kausi romaan “Koju” (Tuum 2012) ning Ülo Pikkovi romaan “Vana prints” (Varrak 2012). Temaatikaga seondub veel teinegi äsja Postimehes ilmunud jutt (Priit Pullerits «Džiibi kaitseks», PM 30.07.2010).')\n",
    "text.tag_layer(['words', 'sentences'])\n",
    "\n",
    "# Apply syntax_ignore_tagger\n",
    "syntax_ignore_tagger = SyntaxIgnoreTagger(ignore_parenthesized_ref=True)\n",
    "syntax_ignore_tagger.tag(text)\n",
    "\n",
    "# Examine results\n",
    "text.syntax_ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flag `ignore_parenthesized_short_char_sequences`\n",
    "\n",
    "Parenthesized short sequences of tokens (up to 4 tokens), each of which also has as short length (up to 4 characters), will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>syntax_ignore</td>\n",
       "      <td>type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>(</b> <b>-66</b> <b>kg</b> <b>)</b></td>\n",
       "      <td>69</td>\n",
       "      <td>79</td>\n",
       "      <td>parentheses_1to3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>(</b> <b>-73</b> <b>kg</b> <b>)</b></td>\n",
       "      <td>103</td>\n",
       "      <td>113</td>\n",
       "      <td>parentheses_1to3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span((, {'normalized_form': None}),\n",
       "Span(-66, {'normalized_form': '-66'}),\n",
       "Span(kg, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None})],\n",
       "SL[Span((, {'normalized_form': None}),\n",
       "Span(-73, {'normalized_form': '-73'}),\n",
       "Span(kg, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None})]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text and preprocess\n",
    "from estnltk.text import Text\n",
    "text = Text('Eesti judokate võistlus jäi laupäeval lühikeseks , nii Joel Rothberg ( -66 kg ) kui ka Renee Villemson ( -73 kg ) võidurõõmu maitsta ei saanud .')\n",
    "text.tag_layer(['words', 'sentences'])\n",
    "\n",
    "# Apply syntax_ignore_tagger\n",
    "syntax_ignore_tagger = SyntaxIgnoreTagger(ignore_parenthesized_short_char_sequences=True)\n",
    "syntax_ignore_tagger.tag(text)\n",
    "\n",
    "# Examine results\n",
    "text.syntax_ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flag `ignore_parenthesized_title_words`\n",
    "\n",
    "Parenthesized 1-2 titlecase words (which may be comma-separated) will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>syntax_ignore</td>\n",
       "      <td>type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>(</b> <b>Rootsi</b> <b>)</b></td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>parentheses_title_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>(</b> <b>Soome</b> <b>)</b></td>\n",
       "      <td>72</td>\n",
       "      <td>81</td>\n",
       "      <td>parentheses_title_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>(</b> <b>Rootsi</b> <b>)</b></td>\n",
       "      <td>101</td>\n",
       "      <td>111</td>\n",
       "      <td>parentheses_title_words</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span((, {'normalized_form': None}),\n",
       "Span(Rootsi, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None})],\n",
       "SL[Span((, {'normalized_form': None}),\n",
       "Span(Soome, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None})],\n",
       "SL[Span((, {'normalized_form': None}),\n",
       "Span(Rootsi, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None})]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text and preprocess\n",
    "from estnltk.text import Text\n",
    "text = Text('Neidude 5 km klassikat võitis Lina Andersson ( Rootsi ) Pirjo Mannineni ( Soome ) ja Karin Holmbergi ( Rootsi ) ees .')\n",
    "text.tag_layer(['words', 'sentences'])\n",
    "\n",
    "# Apply syntax_ignore_tagger\n",
    "syntax_ignore_tagger = SyntaxIgnoreTagger(ignore_parenthesized_title_words=True)\n",
    "syntax_ignore_tagger.tag(text)\n",
    "\n",
    "# Examine results\n",
    "text.syntax_ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flag `ignore_parenthesized_num`\n",
    "\n",
    "Parenthesized numerics (such as dates, date ranges, number sequences) will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>syntax_ignore</td>\n",
       "      <td>type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>(</b><b>1976</b><b>,</b> <b>1977</b><b>,</b> <b>1979</b><b>,</b> <b>1980</b><b>,</b> <b>1982</b><b>,</b> <b>1983</b><b>)</b></td>\n",
       "      <td>41</td>\n",
       "      <td>77</td>\n",
       "      <td>parentheses_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>(</b> <b>21.</b><b>-</b><b>22.</b> <b>mai</b> <b>)</b></td>\n",
       "      <td>88</td>\n",
       "      <td>103</td>\n",
       "      <td>parentheses_num_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>(</b> <b>2.</b><b>-</b><b>3.</b> <b>juuli</b> <b>)</b></td>\n",
       "      <td>115</td>\n",
       "      <td>130</td>\n",
       "      <td>parentheses_num_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>(</b> <b>30.</b><b>-</b><b>31.</b> <b>juuli</b> <b>)</b></td>\n",
       "      <td>143</td>\n",
       "      <td>160</td>\n",
       "      <td>parentheses_num_range</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span((, {'normalized_form': None}),\n",
       "Span(1976, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(1977, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(1979, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(1980, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(1982, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(1983, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None})],\n",
       "SL[Span((, {'normalized_form': None}),\n",
       "Span(21., {'normalized_form': '21'}),\n",
       "Span(-, {'normalized_form': None}),\n",
       "Span(22., {'normalized_form': '22'}),\n",
       "Span(mai, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None})],\n",
       "SL[Span((, {'normalized_form': None}),\n",
       "Span(2., {'normalized_form': '2'}),\n",
       "Span(-, {'normalized_form': None}),\n",
       "Span(3., {'normalized_form': '3'}),\n",
       "Span(juuli, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None})],\n",
       "SL[Span((, {'normalized_form': None}),\n",
       "Span(30., {'normalized_form': '30'}),\n",
       "Span(-, {'normalized_form': None}),\n",
       "Span(31., {'normalized_form': '31'}),\n",
       "Span(juuli, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None})]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text and preprocess\n",
    "from estnltk.text import Text\n",
    "text = Text('Klubi sai kuus korda Inglismaa meistriks (1976, 1977, 1979, 1980, 1982, 1983). Tallinna ( 21.-22. mai ) , Haapsalu ( 2.-3. juuli ) ja Liivimaa ( 30.-31. juuli ) rallidel on vähemalt see probleem lahendatud .')\n",
    "text.tag_layer(['words', 'sentences'])\n",
    "\n",
    "# Apply syntax_ignore_tagger\n",
    "syntax_ignore_tagger = SyntaxIgnoreTagger(ignore_parenthesized_num=True)\n",
    "syntax_ignore_tagger.tag(text)\n",
    "\n",
    "# Examine results\n",
    "text.syntax_ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flag `ignore_parenthesized_num_greedy`\n",
    "\n",
    "Applies greedy parenthesized numeric content detection patterns: if there is at least one number inside parentheses, but there cannot be found at least 3 consecutive lowercase words, then the whole content inside parentheses will be marked as to be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>syntax_ignore</td>\n",
       "      <td>type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>(</b><b>300 000 000</b> <b>m/sek</b><b>)</b></td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>parentheses_num_start_uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>(</b> <b>naised</b> <b>5</b> <b>km</b> <b>,</b> <b>mehed</b> <b>7,5</b> <b>km</b> <b>)</b></td>\n",
       "      <td>33</td>\n",
       "      <td>63</td>\n",
       "      <td>parentheses_num_mid_uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>(</b><b>meie</b> <b>puhul</b> <b>165</b><b>/</b><b>80</b><b>)</b></td>\n",
       "      <td>71</td>\n",
       "      <td>90</td>\n",
       "      <td>parentheses_num_end_uncategorized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span((, {'normalized_form': None}),\n",
       "Span(300 000 000, {'normalized_form': '300000000'}),\n",
       "Span(m/sek, {'normalized_form': 'm/sek'}),\n",
       "Span(), {'normalized_form': None})],\n",
       "SL[Span((, {'normalized_form': None}),\n",
       "Span(naised, {'normalized_form': None}),\n",
       "Span(5, {'normalized_form': None}),\n",
       "Span(km, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(mehed, {'normalized_form': None}),\n",
       "Span(7,5, {'normalized_form': '7,5'}),\n",
       "Span(km, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None})],\n",
       "SL[Span((, {'normalized_form': None}),\n",
       "Span(meie, {'normalized_form': None}),\n",
       "Span(puhul, {'normalized_form': None}),\n",
       "Span(165, {'normalized_form': None}),\n",
       "Span(/, {'normalized_form': None}),\n",
       "Span(80, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None})]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text and preprocess\n",
    "from estnltk.text import Text\n",
    "text = Text('Näited: A (300 000 000 m/sek), B ( naised 5 km , mehed 7,5 km ) ning C (meie puhul 165/80) .')\n",
    "text.tag_layer(['words', 'sentences'])\n",
    "\n",
    "# Apply syntax_ignore_tagger\n",
    "syntax_ignore_tagger = SyntaxIgnoreTagger(ignore_parenthesized_num_greedy=True)\n",
    "syntax_ignore_tagger.tag(text)\n",
    "\n",
    "# Examine results\n",
    "text.syntax_ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this pattern group also covers content detected by some other `ignore_parenthesized_*` patterns. So, if you want to turn other patterns off, you may also want to turn off this pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flag `allow_loose_match`\n",
    "\n",
    "If `True` (default setting), then an ignore text snippet may consume words without matching exactly with their boundaries (e.g. ignore snippet's start does not have to match word's start). If `False`, then an ignore text snippet must match exactly with word boundaries: it must start where a word starts, and end where a word ends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patterns for ignoring full sentences\n",
    "\n",
    "#### Flag  `ignore_sentences_starting_with_time`\n",
    "\n",
    "Sentences starting with a date range (e.g. a time schedule of a seminar, or a TV program) will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>syntax_ignore</td>\n",
       "      <td>type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>12.05</b> <b>-</b> <b>12.35</b> <b>\"</b><b>Õnne</b> <b>13</b><b>\"</b> <b>(</b><b>1.</b> <b>osa</b><b>)</b>\\n<b>12.35</b> <b>-</b> <b>13.05</b> <b>\"</b><b>Õnne</b> <b>13</b><b>\"</b> <b>(</b><b>1.</b> <b>osa</b> <b>kordus</b><b>)</b>\\n<b>13.05</b> <b>-</b> <b>13.35</b> <b>\"</b><b>Õnne</b> <b>13</b><b>\"</b> <b>(</b><b>2.</b> <b>osa</b><b>)</b></td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>sentence_starts_with_time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span(12.05, {'normalized_form': '1205'}),\n",
       "Span(-, {'normalized_form': None}),\n",
       "Span(12.35, {'normalized_form': '1235'}),\n",
       "Span(\", {'normalized_form': None}),\n",
       "Span(Õnne, {'normalized_form': None}),\n",
       "Span(13, {'normalized_form': None}),\n",
       "Span(\", {'normalized_form': None}),\n",
       "Span((, {'normalized_form': None}),\n",
       "Span(1., {'normalized_form': '1'}),\n",
       "Span(osa, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None}),\n",
       "Span(12.35, {'normalized_form': '1235'}),\n",
       "Span(-, {'normalized_form': None}),\n",
       "Span(13.05, {'normalized_form': '1305'}),\n",
       "Span(\", {'normalized_form': None}),\n",
       "Span(Õnne, {'normalized_form': None}),\n",
       "Span(13, {'normalized_form': None}),\n",
       "Span(\", {'normalized_form': None}),\n",
       "Span((, {'normalized_form': None}),\n",
       "Span(1., {'normalized_form': '1'}),\n",
       "Span(osa, {'normalized_form': None}),\n",
       "Span(kordus, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None}),\n",
       "Span(13.05, {'normalized_form': '1305'}),\n",
       "Span(-, {'normalized_form': None}),\n",
       "Span(13.35, {'normalized_form': '1335'}),\n",
       "Span(\", {'normalized_form': None}),\n",
       "Span(Õnne, {'normalized_form': None}),\n",
       "Span(13, {'normalized_form': None}),\n",
       "Span(\", {'normalized_form': None}),\n",
       "Span((, {'normalized_form': None}),\n",
       "Span(2., {'normalized_form': '2'}),\n",
       "Span(osa, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None})]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text and preprocess\n",
    "from estnltk.text import Text\n",
    "text = Text('''\n",
    "12.05 - 12.35 \"Õnne 13\" (1. osa)\n",
    "12.35 - 13.05 \"Õnne 13\" (1. osa kordus)\n",
    "13.05 - 13.35 \"Õnne 13\" (2. osa)\n",
    "''')\n",
    "text.tag_layer(['words', 'sentences'])\n",
    "\n",
    "# Apply syntax_ignore_tagger\n",
    "syntax_ignore_tagger = SyntaxIgnoreTagger(ignore_sentences_starting_with_time=True)\n",
    "syntax_ignore_tagger.tag(text)\n",
    "\n",
    "# Examine results\n",
    "text.syntax_ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flag `ignore_sentences_with_comma_separated_num_name_lists`\n",
    "\n",
    "Sentences containing comma separated list of titlecase words / numbers ( like sport results, player/country listings, game scores etc.) will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>syntax_ignore</td>\n",
       "      <td>type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>Lindsay</b> <b>Davenport</b> <b>(</b> <b>6</b> <b>)</b> <b>,</b> <b>USA-Jana</b> <b>Novotna</b> <b>(</b> <b>3</b> <b>)</b> <b>,</b> <b>Tšehhi</b> <b>6</b> <b>:</b> <b>2 , 4</b> <b>:</b> <b>6 , 7</b> <b>:</b> <b>6</b> <b>,</b> <b>Martina</b> <b>Hingis</b> <b>(</b> <b>1</b> <b>)</b> <b>,</b> <b>Šveits-Arantxa</b> <b>Sanchez</b> <b>Vicario</b> <b>(</b> <b>10</b> <b>)</b> <b>,</b> <b>Hispaania</b> <b>6</b> <b>:</b> <b>3 , 6</b> <b>:</b> <b>2 .</b></td>\n",
       "      <td>19</td>\n",
       "      <td>189</td>\n",
       "      <td>sentence_with_comma_separated_list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>Gigi</b> <b>Fernandez</b> <b>,</b> <b>USA</b><b>/</b><b>Nataša</b> <b>Zvereva</b> <b>,</b> <b>Valgevene-</b> <b>Alexandra</b> <b>Fusai</b><b>/</b><b>Nathalie</b> <b>Tauziat</b> <b>,</b> <b>Prantsusmaa</b> <b>4</b> <b>:</b> <b>6 , 6</b> <b>:</b> <b>2 , 6</b> <b>:</b> <b>2</b> <b>,</b> <b>Nicole</b> <b>Arendt</b> <b>,</b> <b>USA</b><b>/</b><b>Manon</b> <b>Bollegraf</b> <b>,</b> <b>Holland-Ruxandra</b> <b>Dragomir</b> <b>,</b> <b>Rumeenia</b><b>/</b><b>Iva</b> <b>Majoli</b> <b>,</b> <b>Horvaatia</b> <b>6</b> <b>:</b> <b>3 , 3</b> <b>:</b> <b>6 , 6</b> <b>:</b> <b>4 .</b></td>\n",
       "      <td>220</td>\n",
       "      <td>461</td>\n",
       "      <td>sentence_with_comma_separated_list</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span(Lindsay, {'normalized_form': None}),\n",
       "Span(Davenport, {'normalized_form': None}),\n",
       "Span((, {'normalized_form': None}),\n",
       "Span(6, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(USA-Jana, {'normalized_form': None}),\n",
       "Span(Novotna, {'normalized_form': None}),\n",
       "Span((, {'normalized_form': None}),\n",
       "Span(3, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(Tšehhi, {'normalized_form': None}),\n",
       "Span(6, {'normalized_form': None}),\n",
       "Span(:, {'normalized_form': None}),\n",
       "Span(2 , 4, {'normalized_form': '2,4'}),\n",
       "Span(:, {'normalized_form': None}),\n",
       "Span(6 , 7, {'normalized_form': '6,7'}),\n",
       "Span(:, {'normalized_form': None}),\n",
       "Span(6, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(Martina, {'normalized_form': None}),\n",
       "Span(Hingis, {'normalized_form': None}),\n",
       "Span((, {'normalized_form': None}),\n",
       "Span(1, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(Šveits-Arantxa, {'normalized_form': None}),\n",
       "Span(Sanchez, {'normalized_form': None}),\n",
       "Span(Vicario, {'normalized_form': None}),\n",
       "Span((, {'normalized_form': None}),\n",
       "Span(10, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(Hispaania, {'normalized_form': None}),\n",
       "Span(6, {'normalized_form': None}),\n",
       "Span(:, {'normalized_form': None}),\n",
       "Span(3 , 6, {'normalized_form': '3,6'}),\n",
       "Span(:, {'normalized_form': None}),\n",
       "Span(2 ., {'normalized_form': '2'})],\n",
       "SL[Span(Gigi, {'normalized_form': None}),\n",
       "Span(Fernandez, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(USA, {'normalized_form': None}),\n",
       "Span(/, {'normalized_form': None}),\n",
       "Span(Nataša, {'normalized_form': None}),\n",
       "Span(Zvereva, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(Valgevene-, {'normalized_form': 'Valgevene'}),\n",
       "Span(Alexandra, {'normalized_form': None}),\n",
       "Span(Fusai, {'normalized_form': None}),\n",
       "Span(/, {'normalized_form': None}),\n",
       "Span(Nathalie, {'normalized_form': None}),\n",
       "Span(Tauziat, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(Prantsusmaa, {'normalized_form': None}),\n",
       "Span(4, {'normalized_form': None}),\n",
       "Span(:, {'normalized_form': None}),\n",
       "Span(6 , 6, {'normalized_form': '6,6'}),\n",
       "Span(:, {'normalized_form': None}),\n",
       "Span(2 , 6, {'normalized_form': '2,6'}),\n",
       "Span(:, {'normalized_form': None}),\n",
       "Span(2, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(Nicole, {'normalized_form': None}),\n",
       "Span(Arendt, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(USA, {'normalized_form': None}),\n",
       "Span(/, {'normalized_form': None}),\n",
       "Span(Manon, {'normalized_form': None}),\n",
       "Span(Bollegraf, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(Holland-Ruxandra, {'normalized_form': None}),\n",
       "Span(Dragomir, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(Rumeenia, {'normalized_form': None}),\n",
       "Span(/, {'normalized_form': None}),\n",
       "Span(Iva, {'normalized_form': None}),\n",
       "Span(Majoli, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(Horvaatia, {'normalized_form': None}),\n",
       "Span(6, {'normalized_form': None}),\n",
       "Span(:, {'normalized_form': None}),\n",
       "Span(3 , 3, {'normalized_form': '3,3'}),\n",
       "Span(:, {'normalized_form': None}),\n",
       "Span(6 , 6, {'normalized_form': '6,6'}),\n",
       "Span(:, {'normalized_form': None}),\n",
       "Span(4 ., {'normalized_form': '4'})]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text and preprocess\n",
    "from estnltk.text import Text\n",
    "text = Text('''\n",
    "Veerandfinaalid .\n",
    "Lindsay Davenport ( 6 ) , USA-Jana Novotna ( 3 ) , Tšehhi 6 : 2 , 4 : 6 , 7 : 6 , Martina Hingis ( 1 ) , Šveits-Arantxa Sanchez Vicario ( 10 ) , Hispaania 6 : 3 , 6 : 2 .\n",
    "Paarismängu veerandfinaalid .\n",
    "Gigi Fernandez , USA/Nataša Zvereva , Valgevene- Alexandra Fusai/Nathalie Tauziat , Prantsusmaa 4 : 6 , 6 : 2 , 6 : 2 , Nicole Arendt , USA/Manon Bollegraf , Holland-Ruxandra Dragomir , Rumeenia/Iva Majoli , Horvaatia 6 : 3 , 3 : 6 , 6 : 4 .\n",
    "''')\n",
    "text.tag_layer(['words', 'sentences'])\n",
    "\n",
    "# Apply syntax_ignore_tagger\n",
    "syntax_ignore_tagger = SyntaxIgnoreTagger(ignore_sentences_with_comma_separated_num_name_lists=True)\n",
    "syntax_ignore_tagger.tag(text)\n",
    "\n",
    "# Examine results\n",
    "text.syntax_ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flag  `ignore_sentences_consisting_of_numbers`\n",
    "\n",
    "Detects sentences that only contain number or numbers, no letters, and do not end with '!' nor '?'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patterns for ignoring groups of consecutive sentences\n",
    "\n",
    "#### Flag  `ignore_consecutive_parenthesized_sentences `\n",
    "\n",
    "If consecutive sentences all contain parenthesized content that is already ignored, and all of these sentences contain less than 3 consecutive lowercase words, then these sentences likely represent enumerations (e.g. sports results) which can be safely ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>syntax_ignore</td>\n",
       "      <td>type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>Tulemused</b> <b>:</b>\\n<b>1.</b></td>\n",
       "      <td>82</td>\n",
       "      <td>96</td>\n",
       "      <td>consecutive_enum_ucase_sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>Tommi</b> <b>Mäkinen</b> <b>(</b> <b>FIN</b> <b>)</b> <b>Mitsubishi</b> <b>-</b> <b>3.46 , 9</b>\\n<b>2.</b></td>\n",
       "      <td>97</td>\n",
       "      <td>143</td>\n",
       "      <td>consecutive_parenthesized_sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>Marcus</b> <b>Grönholm</b> <b>(</b> <b>FIN</b> <b>)</b> <b>Peugeot</b> <b>+1,0</b>\\n<b>3.</b></td>\n",
       "      <td>144</td>\n",
       "      <td>183</td>\n",
       "      <td>consecutive_parenthesized_sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>Harri</b> <b>Rovanperä</b> <b>(</b> <b>FIN</b> <b>)</b> <b>Peugeot</b> <b>+4,1</b>\\n<b>4.</b></td>\n",
       "      <td>184</td>\n",
       "      <td>223</td>\n",
       "      <td>consecutive_parenthesized_sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>Carlos</b> <b>Sainz</b> <b>(</b> <b>ESP</b> <b>)</b> <b>Ford</b> <b>+6,0</b></td>\n",
       "      <td>224</td>\n",
       "      <td>254</td>\n",
       "      <td>consecutive_parenthesized_sentences</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span(Tulemused, {'normalized_form': None}),\n",
       "Span(:, {'normalized_form': None}),\n",
       "Span(1., {'normalized_form': '1'})],\n",
       "SL[Span(Tommi, {'normalized_form': None}),\n",
       "Span(Mäkinen, {'normalized_form': None}),\n",
       "Span((, {'normalized_form': None}),\n",
       "Span(FIN, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None}),\n",
       "Span(Mitsubishi, {'normalized_form': None}),\n",
       "Span(-, {'normalized_form': None}),\n",
       "Span(3.46 , 9, {'normalized_form': '346 , 9'}),\n",
       "Span(2., {'normalized_form': '2'})],\n",
       "SL[Span(Marcus, {'normalized_form': None}),\n",
       "Span(Grönholm, {'normalized_form': None}),\n",
       "Span((, {'normalized_form': None}),\n",
       "Span(FIN, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None}),\n",
       "Span(Peugeot, {'normalized_form': None}),\n",
       "Span(+1,0, {'normalized_form': '+1,0'}),\n",
       "Span(3., {'normalized_form': '3'})],\n",
       "SL[Span(Harri, {'normalized_form': None}),\n",
       "Span(Rovanperä, {'normalized_form': None}),\n",
       "Span((, {'normalized_form': None}),\n",
       "Span(FIN, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None}),\n",
       "Span(Peugeot, {'normalized_form': None}),\n",
       "Span(+4,1, {'normalized_form': '+4,1'}),\n",
       "Span(4., {'normalized_form': '4'})],\n",
       "SL[Span(Carlos, {'normalized_form': None}),\n",
       "Span(Sainz, {'normalized_form': None}),\n",
       "Span((, {'normalized_form': None}),\n",
       "Span(ESP, {'normalized_form': None}),\n",
       "Span(), {'normalized_form': None}),\n",
       "Span(Ford, {'normalized_form': None}),\n",
       "Span(+6,0, {'normalized_form': '+6,0'})]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text and preprocess\n",
    "from estnltk.text import Text\n",
    "text = Text('''Eile õhtul sõidetud avakatsel sai Markko Märtin ( Subaru , pildil ) viienda aja .\n",
    "Tulemused :\n",
    "1. Tommi Mäkinen ( FIN ) Mitsubishi - 3.46 , 9\n",
    "2. Marcus Grönholm ( FIN ) Peugeot +1,0\n",
    "3. Harri Rovanperä ( FIN ) Peugeot +4,1\n",
    "4. Carlos Sainz ( ESP ) Ford +6,0''')\n",
    "text.tag_layer(['words', 'sentences'])\n",
    "\n",
    "# Apply syntax_ignore_tagger\n",
    "syntax_ignore_tagger = SyntaxIgnoreTagger(ignore_consecutive_parenthesized_sentences=True)\n",
    "syntax_ignore_tagger.tag(text)\n",
    "\n",
    "# Examine results\n",
    "text.syntax_ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flag  `ignore_consecutive_enum_ucase_num_sentences`\n",
    "\n",
    "Detects sentences that: 1) start with an uppercase letter, or an ordinal number followed by an uppercase letter, or an ordinal number; 2) contain at least one number; 3) does not contain 3 consecutive lowercase words; 4) are a part of at least 4 consecutive sentences that have the same properties (1, 2 and 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>syntax_ignore</td>\n",
       "      <td>type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>Harjumaa</b> <b>2792</b> <b>,</b>\\n<b>2.</b></td>\n",
       "      <td>64</td>\n",
       "      <td>82</td>\n",
       "      <td>consecutive_enum_ucase_sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>Hiiumaa</b> <b>2119</b> <b>,</b>\\n<b>3.</b></td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>consecutive_enum_ucase_sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>Tartumaa</b> <b>2081</b> <b>,</b>\\n<b>4.</b></td>\n",
       "      <td>101</td>\n",
       "      <td>119</td>\n",
       "      <td>consecutive_enum_ucase_sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>Läänemaa</b> <b>1933</b> <b>,</b>\\n<b>5.</b></td>\n",
       "      <td>120</td>\n",
       "      <td>138</td>\n",
       "      <td>consecutive_enum_ucase_sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>Pärnumaa</b> <b>1903.</b></td>\n",
       "      <td>139</td>\n",
       "      <td>153</td>\n",
       "      <td>consecutive_enum_ucase_sentences</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[Span(Harjumaa, {'normalized_form': None}),\n",
       "Span(2792, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(2., {'normalized_form': '2'})],\n",
       "SL[Span(Hiiumaa, {'normalized_form': None}),\n",
       "Span(2119, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(3., {'normalized_form': '3'})],\n",
       "SL[Span(Tartumaa, {'normalized_form': None}),\n",
       "Span(2081, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(4., {'normalized_form': '4'})],\n",
       "SL[Span(Läänemaa, {'normalized_form': None}),\n",
       "Span(1933, {'normalized_form': None}),\n",
       "Span(,, {'normalized_form': None}),\n",
       "Span(5., {'normalized_form': '5'})],\n",
       "SL[Span(Pärnumaa, {'normalized_form': None}),\n",
       "Span(1903., {'normalized_form': '1903'})]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text and preprocess\n",
    "from estnltk.text import Text\n",
    "text = Text('''Maakonniti summeerides on tulumaksu laekumise viis esimest :\n",
    "1. Harjumaa 2792 ,\n",
    "2. Hiiumaa 2119 ,\n",
    "3. Tartumaa 2081 ,\n",
    "4. Läänemaa 1933 ,\n",
    "5. Pärnumaa 1903.''')\n",
    "text.tag_layer(['words', 'sentences'])\n",
    "\n",
    "# Apply syntax_ignore_tagger\n",
    "syntax_ignore_tagger = SyntaxIgnoreTagger(ignore_consecutive_enum_ucase_num_sentences=True)\n",
    "syntax_ignore_tagger.tag(text)\n",
    "\n",
    "# Examine results\n",
    "text.syntax_ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with the syntactic analysis pre-processing module\n",
    "\n",
    "Integration with the syntactic analysis pre-processing module is yet to be implemented."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
