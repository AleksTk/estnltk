{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw text taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RegexTagger\n",
    "\n",
    "For initialisation RegexTagger needs the vocabulary. Vocabulary argument may be a csv file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = 'raw_text_taggers/vocabulary.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_regex_pattern_</th>\n",
       "      <th>_group_</th>\n",
       "      <th>_priority_</th>\n",
       "      <th>normalized</th>\n",
       "      <th>comment</th>\n",
       "      <th>example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-?(\\d[\\s\\.]?)+(,\\s?(\\d[\\s\\.]?)+)?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>lambda m: re.sub('[\\s\\.]' ,'' , m.group(0))</td>\n",
       "      <td>number</td>\n",
       "      <td>-34 567 000 123 , 456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>lambda m: None</td>\n",
       "      <td>e-mail</td>\n",
       "      <td>bla@bla.bl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    _regex_pattern_  _group_  _priority_  \\\n",
       "0                 -?(\\d[\\s\\.]?)+(,\\s?(\\d[\\s\\.]?)+)?        0           1   \n",
       "1  ([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)        1           2   \n",
       "\n",
       "                                    normalized comment                example  \n",
       "0  lambda m: re.sub('[\\s\\.]' ,'' , m.group(0))  number  -34 567 000 123 , 456  \n",
       "1                               lambda m: None  e-mail             bla@bla.bl  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "vocabulary = read_csv(vocabulary, na_filter=False, index_col=False)\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or a list of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_group_': 0,\n",
       "  '_priority_': 1,\n",
       "  '_regex_pattern_': '-?(\\\\d[\\\\s\\\\.]?)+(,\\\\s?(\\\\d[\\\\s\\\\.]?)+)?',\n",
       "  'comment': 'number',\n",
       "  'example': '-34 567 000 123 , 456',\n",
       "  'normalized': \"lambda m: re.sub('[\\\\s\\\\.]' ,'' , m.group(0))\"},\n",
       " {'_group_': 1,\n",
       "  '_priority_': 2,\n",
       "  '_regex_pattern_': '([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\\\.[a-zA-Z0-9-.]+)',\n",
       "  'comment': 'e-mail',\n",
       "  'example': 'bla@bla.bl',\n",
       "  'normalized': 'lambda m: None'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = vocabulary.to_dict('records')\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The required keywords are **term**, **group**, **priority**. The banned keywords are **start** and **end**.\n",
    "\n",
    "**term** is a regular expression, **group** determines which part of the term should be tagged on the text, **priority** is used to resolve conflicts.\n",
    "\n",
    "In case of intersecting spans, the span with smaller priority is removed, if priorities are equal, the span with bigger start or end is removed.\n",
    "\n",
    "Any string (except the term strings) which starts with 'lambda m:' is evaluated as a lambda function with argument m, the match object. That function should return the value for the corresponding attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conflicts': 0}\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SL[Span(bla@bla.ee, {'normalized': None}),\n",
       "Span(10 456 , {'normalized': '10456'}),\n",
       "Span(foo@foo.ee, {'normalized': None}),\n",
       "Span(10 , {'normalized': '10'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import RegexTagger\n",
    "from estnltk import Text\n",
    "\n",
    "tokenization_hints_tagger = RegexTagger(vocabulary=vocabulary,\n",
    "                                        attributes={'normalized'},\n",
    "                                        layer_name='tokenization_hints')\n",
    "\n",
    "text = Text('Aadressilt bla@bla.ee tuli 10 456 kirja aadressile foo@foo.ee 10 tunni jooksul.')\n",
    "\n",
    "status = {}\n",
    "tokenization_hints_tagger.tag(text, status)\n",
    "print(status)\n",
    "print(tokenization_hints_tagger._number_of_conflicts)\n",
    "text.tokenization_hints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
