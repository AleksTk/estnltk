{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing files of Estonian Reference Corpus (_Eesti keele koondkorpus_)\n",
    "\n",
    "EstNLTK contains tools specifically created for processing Estonian Reference Corpus (_Eesti keele koondkorpus_). \n",
    "These tools can be used for importing XML TEI format files, and converting to EstNLTK Text objects.\n",
    "In this tutorial, we provide an overview about how koondkorpus files can be processed with EstNLTK (and what are the current limitations of processing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Koondkorpus XML files\n",
    "\n",
    "The page [http://www.cl.ut.ee/korpused/segakorpus/](http://www.cl.ut.ee/korpused/segakorpus/) lists all the subcorpora of Estonian Reference Corpus. There, you can follow the links and download (zipped) XML files of the corpus. \n",
    "\n",
    "Once you have downloaded a zipped XML corpus and unzipped it, you should see a folder structure similar to this:\n",
    "\n",
    "\n",
    "        ├── Kroonika\n",
    "        │   ├── bin\n",
    "        │   │   ├── koondkorpus_main_header.xml\n",
    "        │   │   └── tei_corpus.rng\n",
    "        │   └── Kroon\n",
    "        │       ├── bin\n",
    "        │       │   └── header_aja_kroonika.xml\n",
    "        │       └── kroonika\n",
    "        │           ├── kroonika_2000\n",
    "        │           │   ├── aja_kr_2000_12_08.xml\n",
    "        │           │   ├── aja_kr_2000_12_15.xml\n",
    "        │           │   ├── aja_kr_2000_12_22.xml\n",
    "        │           │   └── aja_kr_2000_12_29.xml\n",
    "        │           ├── kroonika_2001\n",
    "        │           │   ├── aja_kr_2001_01_05.xml\n",
    "        │           │   ├── aja_kr_2001_01_12.xml\n",
    "        │           │   ├── aja_kr_2001_01_19.xml\n",
    "        │           │   ├── aja_kr_2001_01_22.xml\n",
    "        ...         ...     ...\n",
    "        \n",
    "        \n",
    "<center>Example. Folder structure in _Kroonika.zip_</center>\n",
    "\n",
    "Folders `'bin'` contain headers and corpus descriptions. The `'.xml'` files outside the `'bin'` folders are the files with the actual textual content. These files can be analysed with EstNLTK.\n",
    "\n",
    "\n",
    "#### Loading texts from XML TEI files\n",
    "\n",
    "The module `estnltk.corpus_processing.parse_koondkorpus` allows to import texts and metadata from XML TEI files, and store in `Text` objects. The following functions are available for wider usage:\n",
    "\n",
    "  * `parse_tei_corpus(path, target=['artikkel'], encoding='utf-8', preserve_tokenization=False, record_xml_filename=False)` -- reads and parses a single XML file (given with the full `path`), creates `Text` objects storing documents and metadata from the file, and returns a list of created `Text` objects;\n",
    "\n",
    "\n",
    "  * `parse_tei_corpora(root, prefix='', suffix='.xml', target=['artikkel'], encoding='utf-8', preserve_tokenization=False,  record_xml_filename=False)` -- reads recursively all the files from the directory `root`, selects files with the given `prefix` and `suffix` for XML parsing, and creates `Text` objects storing documents and metadata from files. Returns a list of created `Text` objects;\n",
    "  \n",
    "\n",
    "**Arguments**\n",
    "\n",
    "Exact behaviour of the functions can be modified by the following common arguments:\n",
    "\n",
    "* **`target`** -- specifies the list of types of divs, from which the textual content is to be extacted. For instance, in case of newspaper articles, the content of an article is typically between `<div3 type=\"artikkel\">` and `</div3>`, so, you should use `target=['artikkel']`. In case of fiction writings, the content of a single work is typically between `<div1 type=\"tervikteos\">` and `</div1>`, and you may want to use `target=['tervikteos']`.\n",
    "\n",
    "  Which are the correct type values for `target` depends on the goal of analysis. For example, you may want to divide a fiction text into chapters, instead of analysing it as a whole. In such case, you should manually look up the correct type values (for chapters) from the concrete XML file.\n",
    "  \n",
    "  If you do not have very specific goals, you can use the function **`get_div_target()`**, which provides a reasonable default div type for the given XML file, based on the hard-coded values. Example:\n",
    "\n",
    "       from estnltk.corpus_processing.parse_koondkorpus import get_div_target, parse_tei_corpus\n",
    "       xml_file = \"/home/siim/koond/Eesti_ilukirjandus/ilukirjandus/Eesti_ilukirjandus_1990/ilu_ahasveerus.tasak.xml\"\n",
    "       target = get_div_target( xml_file )    # note: returns a single value, not list\n",
    "       docs = parse_tei_corpus( xml_file, target=[target] )\n",
    "  \n",
    "     Note: the function `get_div_target()` needs name of the xml file with full path, as it uses information from directory names for determining the div type.\n",
    "\n",
    "\n",
    "* **`preserve_tokenization`** -- specifies if the original paragraph and sentence tokenization in the XML files should be preserved (default: False). If switched on, then not only `Text` objects are created, but they are also annotated with layers `'words'`, `'sentences'` and `'paragraphs'`, trying to preserve the original tokenization. This means that sentences are taken from between `<s>` and `</s>` tags, and paragraphs from between `<p>` and `</p>` tags.\n",
    "\n",
    "     _Note 1_: Creating tokenization layers also means longer processing times. So, processing with `preserve_tokenization=True` takes longer than processing with `preserve_tokenization=False` (the default setting);\n",
    "     \n",
    "     _Note 2_: If you need to, you can still restore the original tokenization, even if you use `preserve_tokenization=False`. In the created `Text` objects, paragraphs are separated by two newlines and sentences by a single newline. You can use `SentenceTokenizer` with the `base_sentence_tokenizer` set to NLTK's `LineTokenizer()` to get the correct sentence segmentation (and the default paragraph tokenizer should be able to provide correct paragraph tokenization);\n",
    "\n",
    "\n",
    "* **`record_xml_filename`** -- specifies if the name of XML file should recorded in the metadata of the created `Text` objects, under the key `'_xml_file'` (default: False);\n",
    "\n",
    "\n",
    "* **`encoding`** -- encoding of the input file (or input files). Normally, you should go with the default value ('utf-8')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing whole koondkorpus with EstNLTK\n",
    "\n",
    "TODO\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
