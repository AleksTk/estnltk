{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (text.py, line 14)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\rasmusm\\AppData\\Local\\Continuum\\anaconda3\\envs\\py35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m2961\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-2-3e1bfcc446aa>\"\u001b[0m, line \u001b[0;32m1\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    import estnltk\n",
      "  File \u001b[0;32m\"C:\\Users\\rasmusm\\Documents\\estnltk\\estnltk\\__init__.py\"\u001b[0m, line \u001b[0;32m12\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from estnltk.layer.layer import Layer\n",
      "  File \u001b[0;32m\"C:\\Users\\rasmusm\\Documents\\estnltk\\estnltk\\layer\\layer.py\"\u001b[0m, line \u001b[0;32m588\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    import estnltk.layer_operations as layer_operations\n",
      "  File \u001b[0;32m\"C:\\Users\\rasmusm\\Documents\\estnltk\\estnltk\\layer_operations\\__init__.py\"\u001b[0m, line \u001b[0;32m21\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from .splitting import extract_section\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\rasmusm\\Documents\\estnltk\\estnltk\\layer_operations\\splitting.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from estnltk.text import Text\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\rasmusm\\Documents\\estnltk\\estnltk\\text.py\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    methods: Set[str] = {\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import estnltk\n",
    "from estnltk import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from estnltk.taggers.estner.refac.ner import NerTagger\n",
    "ntager = NerTagger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "textobject2 = Text(\"Eesti Vabariik on riik Põhja-Euroopas. Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers': [],\n",
       " 'meta': {},\n",
       " 'text': 'Eesti Vabariik on riik Põhja-Euroopas. Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.converters import text_to_dict\n",
    "\n",
    "text_to_dict(textobject2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers.estner.ner_tagger import NerTagger as nt2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nertagger = nt2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Eesti Vabariik on riik Põhja-Euroopas. Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag, name</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Eesti Vabariik on riik Põhja-Euroopas. Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nertagger.tag(textobject2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag, name</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>nertag</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Eesti', 'Vabariik']</td>\n",
       "      <td>LOC</td>\n",
       "      <td>po</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Põhja-Euroopas']</td>\n",
       "      <td>LOC</td>\n",
       "      <td>po</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Eesti']</td>\n",
       "      <td>LOC</td>\n",
       "      <td>po</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Soome', 'lahe', 'Soome', 'Vabariigiga']</td>\n",
       "      <td>LOC</td>\n",
       "      <td>po</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='ner', attributes=('nertag', 'name'), spans=SL[EnvelopingSpan(['Eesti', 'Vabariik'], [{'nertag': 'LOC', 'name': 'po'}]),\n",
       "EnvelopingSpan(['Põhja-Euroopas'], [{'nertag': 'LOC', 'name': 'po'}]),\n",
       "EnvelopingSpan(['Eesti'], [{'nertag': 'LOC', 'name': 'po'}]),\n",
       "EnvelopingSpan(['Soome', 'lahe', 'Soome', 'Vabariigiga'], [{'nertag': 'LOC', 'name': 'po'}])])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textobject2.ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseFeatureExtractor(object):\n",
    "    \"\"\"Base class for all feature extractors.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def prepare(self, docs):\n",
    "        ''' Called before feature extraction actually happens. Can be used to \n",
    "        collect global statistics on the corpus. '''\n",
    "        pass\n",
    "\n",
    "    def process(self, doc):\n",
    "        for token in doc.tokens:\n",
    "            self._process(token)\n",
    "\n",
    "    def _process(self, token):\n",
    "        raise NotImplementedError(\"Not implemented!\")\n",
    "\n",
    "\n",
    "class MorphFeatureExtractor(BaseFeatureExtractor):\n",
    "    \"\"\"Extracts features provided by the morphological analyser pyvabamorf. \"\"\"\n",
    "\n",
    "    def _process(self, t):\n",
    "        LEM = \"lem\"\n",
    "        POS = \"pos\"\n",
    "        PROP = \"prop\"\n",
    "        PREF = \"pref\"\n",
    "        POST = \"post\"\n",
    "        CASE = \"case\"\n",
    "        END = \"end\"\n",
    "        PUN = \"pun\"\n",
    "        t[LEM] = get_lemma(t.lemma)\n",
    "        t[POS] = get_pos(t.morph)\n",
    "        t[PROP] = b(is_prop(t.morph))\n",
    "        t[PREF], t[POST] = get_word_parts(t.lemma)\n",
    "        t[CASE] = get_case(t.morph)\n",
    "        t[END] = get_ending(t.lemma)\n",
    "        t[PUN] = b(t[POS] == '_Z_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(token):\n",
    "    r = u''\n",
    "    for c in token:\n",
    "        if c.isupper():\n",
    "            r += 'U'\n",
    "        elif c.islower():\n",
    "            r += 'L'\n",
    "        elif c.isdigit():\n",
    "            r += 'D'\n",
    "        elif c in ('.', ','):\n",
    "            r += '.'\n",
    "        elif c in (';', ':', '?', '!'):\n",
    "            r += ';'\n",
    "        elif c in ('+', '-', '*', '/', '=', '|', '_'):\n",
    "            r += '-'\n",
    "        elif c in ('(', '{', '[', '<'):\n",
    "            r += '('\n",
    "        elif c in (')', '}', ']', '>'):\n",
    "            r += ')'\n",
    "        else:\n",
    "            r += c\n",
    "    return r\n",
    "\n",
    "\n",
    "def degenerate(src):\n",
    "    dst = u''\n",
    "    for c in src:\n",
    "        if not dst or dst[-1] != c:\n",
    "            dst += c\n",
    "    return dst\n",
    "\n",
    "\n",
    "def get_2d(token):\n",
    "    return len(token) == 2 and token.isdigit()\n",
    "\n",
    "\n",
    "def get_4d(token):\n",
    "    return len(token) == 4 and token.isdigit()\n",
    "\n",
    "\n",
    "def get_da(token):\n",
    "    bd = False\n",
    "    ba = False\n",
    "    for c in token:\n",
    "        if c.isdigit():\n",
    "            bd = True\n",
    "        elif c.isalpha():\n",
    "            ba = True\n",
    "        else:\n",
    "            return False\n",
    "    return bd and ba\n",
    "\n",
    "\n",
    "def get_dand(token, p):\n",
    "    bd = False\n",
    "    bdd = False\n",
    "    for c in token:\n",
    "        if c.isdigit():\n",
    "            bd = True\n",
    "        elif c == p:\n",
    "            bdd = True\n",
    "        else:\n",
    "            return False\n",
    "    return bd and bdd\n",
    "\n",
    "\n",
    "def get_all_other(token):\n",
    "    for c in token:\n",
    "        if c.isalnum():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_capperiod(token):\n",
    "    return len(token) == 2 and token[0].isupper() and token[1] == '.'\n",
    "\n",
    "\n",
    "def contains_upper(token):\n",
    "    b = False\n",
    "    for c in token:\n",
    "        b |= c.isupper()\n",
    "    return b\n",
    "\n",
    "\n",
    "def contains_lower(token):\n",
    "    b = False\n",
    "    for c in token:\n",
    "        b |= c.islower()\n",
    "    return b\n",
    "\n",
    "\n",
    "def contains_alpha(token):\n",
    "    b = False\n",
    "    for c in token:\n",
    "        b |= c.isalpha()\n",
    "    return b\n",
    "\n",
    "\n",
    "def contains_digit(token):\n",
    "    b = False\n",
    "    for c in token:\n",
    "        b |= c.isdigit()\n",
    "    return b\n",
    "\n",
    "\n",
    "def contains_symbol(token):\n",
    "    for c in token:\n",
    "        if not c.isalnum():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def split_char(token, char):\n",
    "    return token.split(char, 1) if token.find(char) > -1 else [None, None]\n",
    "\n",
    "\n",
    "def b(v):\n",
    "    return 'y' if v else None\n",
    "\n",
    "\n",
    "# morphological features\n",
    "def get_lemma(morph_lemma):\n",
    "    if len(morph_lemma) > 1:\n",
    "        ridx = morph_lemma.rfind(\"=\")\n",
    "        if ridx == -1: ridx = morph_lemma.rfind(\"+\")\n",
    "        if ridx == -1: ridx = len(morph_lemma)\n",
    "        if ridx > 0:\n",
    "            morph_lemma = morph_lemma[:ridx]\n",
    "        lemma = re.sub(r'(?<=[^\\W_])_(?=[^\\W_])', '', morph_lemma)\n",
    "    else:\n",
    "        lemma = morph_lemma\n",
    "    return lemma.lower()\n",
    "\n",
    "\n",
    "def get_word_parts(morph_lemma):\n",
    "    ridx = morph_lemma.rfind(\"=\")\n",
    "    if ridx == -1: ridx = morph_lemma.rfind(\"+\")\n",
    "    if ridx == -1: ridx = len(morph_lemma)\n",
    "    lemma = morph_lemma[:ridx]\n",
    "    lemma = lemma.lower()\n",
    "    chunks = lemma.split(\"_\")\n",
    "    if len(chunks) > 1:\n",
    "        prefix, postfix = chunks[0], chunks[-1]\n",
    "    else:\n",
    "        prefix, postfix = None, None\n",
    "    return prefix, postfix\n",
    "\n",
    "\n",
    "def get_case(morph):\n",
    "    if morph.startswith(\"_S_\") or morph.startswith(\"_H_\"):\n",
    "        try:\n",
    "            case = morph[morph.rindex(\" \") + 1: len(morph)]\n",
    "        except ValueError:\n",
    "            case = None\n",
    "    else:\n",
    "        case = None\n",
    "    return case\n",
    "\n",
    "\n",
    "def get_ending(morph_lemma):\n",
    "    try:\n",
    "        end = morph_lemma[morph_lemma.index(\"+\") + 1:]\n",
    "    except ValueError:\n",
    "        return None\n",
    "    if end == \"0\":\n",
    "        return None\n",
    "    else:\n",
    "        return end\n",
    "\n",
    "\n",
    "def get_pos(morph):\n",
    "    pos = morph.split()[0]\n",
    "    return pos\n",
    "\n",
    "\n",
    "def is_prop(morph):\n",
    "    return morph.split()[0] == \"_H_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MorphFeatureExtractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6830cb56ba22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmfe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMorphFeatureExtractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'MorphFeatureExtractor' is not defined"
     ]
    }
   ],
   "source": [
    "mfe = MorphFeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers.estner.refac.ner import json_document_to_estner_document\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nerdoc = json_document_to_estner_document(textobject2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Eesti Vabariik on riik Põhja-Euroopas. Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag, name</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Eesti Vabariik on riik Põhja-Euroopas. Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textobject2.tag_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">Eesti</span></span></td>\n",
       "      <td>Eesti</td>\n",
       "      <td>Eesti</td>\n",
       "      <td>Eesti</td>\n",
       "      <td>[&#x27;Eesti&#x27;]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('Eesti', [{'normalized_text': 'Eesti', 'lemma': 'Eesti', 'root': 'Eesti', 'root_tokens': ['Eesti'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'H'}])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textobject2.morph_analysis[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lem': 'eesti', 'pos': '_H_', 'prop': 'y', 'case': 'g'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'F'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-cb6872fa6126>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\estnltk\\estnltk\\taggers\\estner\\ner.py\u001b[0m in \u001b[0;36mfeature_list\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__unicode__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'F'"
     ]
    }
   ],
   "source": [
    "for token in nerdoc.tokens:\n",
    "    token2 = deepcopy(token)\n",
    "    mfe._process(token2)\n",
    "    print(token2)\n",
    "    print(token2.feature_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-6a62f369af25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnerdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "mfe._process(nerdoc.tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eesti Vabariik on riik Põhja-Euroopas . Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga ."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nerdoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sisend = [{'named_entities': [{'end': 14, 'label': 'LOC', 'start': 0},\n",
    "   {'end': 37, 'label': 'LOC', 'start': 23}],\n",
    "  'paragraphs': [{'end': 43, 'start': 0}],\n",
    "  'sentences': [{'end': 38, 'start': 0}],\n",
    "  'text': 'Eesti Vabariik on riik Põhja-Euroopas.\\n    ',\n",
    "  'words': [{'analysis': [{'clitic': '',\n",
    "      'ending': '0',\n",
    "      'form': 'sg g',\n",
    "      'lemma': 'Eesti',\n",
    "      'partofspeech': 'H',\n",
    "      'root': 'Eesti',\n",
    "      'root_tokens': ['Eesti']}],\n",
    "    'end': 5,\n",
    "    'label': 'B-LOC',\n",
    "    'start': 0,\n",
    "    'text': 'Eesti'},\n",
    "   {'analysis': [{'clitic': '',\n",
    "      'ending': '0',\n",
    "      'form': 'sg n',\n",
    "      'lemma': 'vabariik',\n",
    "      'partofspeech': 'S',\n",
    "      'root': 'vaba_riik',\n",
    "      'root_tokens': ['vaba', 'riik']}],\n",
    "    'end': 14,\n",
    "    'label': 'I-LOC',\n",
    "    'start': 6,\n",
    "    'text': 'Vabariik'},\n",
    "   {'analysis': [{'clitic': '',\n",
    "      'ending': '0',\n",
    "      'form': 'b',\n",
    "      'lemma': 'olema',\n",
    "      'partofspeech': 'V',\n",
    "      'root': 'ole',\n",
    "      'root_tokens': ['ole']},\n",
    "     {'clitic': '',\n",
    "      'ending': '0',\n",
    "      'form': 'vad',\n",
    "      'lemma': 'olema',\n",
    "      'partofspeech': 'V',\n",
    "      'root': 'ole',\n",
    "      'root_tokens': ['ole']}],\n",
    "    'end': 17,\n",
    "    'label': 'O',\n",
    "    'start': 15,\n",
    "    'text': 'on'},\n",
    "   {'analysis': [{'clitic': '',\n",
    "      'ending': '0',\n",
    "      'form': 'sg n',\n",
    "      'lemma': 'riik',\n",
    "      'partofspeech': 'S',\n",
    "      'root': 'riik',\n",
    "      'root_tokens': ['riik']}],\n",
    "    'end': 22,\n",
    "    'label': 'O',\n",
    "    'start': 18,\n",
    "    'text': 'riik'},\n",
    "   {'analysis': [{'clitic': '',\n",
    "      'ending': 's',\n",
    "      'form': 'sg in',\n",
    "      'lemma': 'Põhja-Euroobas',\n",
    "      'partofspeech': 'H',\n",
    "      'root': 'Põhja-Eu_roobas',\n",
    "      'root_tokens': ['Põhja', 'Eu', 'roobas']},\n",
    "     {'clitic': '',\n",
    "      'ending': 's',\n",
    "      'form': 'sg in',\n",
    "      'lemma': 'Põhja-Euroopa',\n",
    "      'partofspeech': 'H',\n",
    "      'root': 'Põhja-Euroopa',\n",
    "      'root_tokens': ['Põhja', 'Euroopa']}],\n",
    "    'end': 37,\n",
    "    'label': 'B-LOC',\n",
    "    'start': 23,\n",
    "    'text': 'Põhja-Euroopas'},\n",
    "   {'analysis': [{'clitic': '',\n",
    "      'ending': '',\n",
    "      'form': '',\n",
    "      'lemma': '.',\n",
    "      'partofspeech': 'Z',\n",
    "      'root': '.',\n",
    "      'root_tokens': ['.']}],\n",
    "    'end': 38,\n",
    "    'label': 'O',\n",
    "    'start': 37,\n",
    "    'text': '.'}]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tagged2 = ntager.tag_documents([textobject2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag, name</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>nertag</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Eesti', 'Vabariik']</td>\n",
       "      <td>LOC</td>\n",
       "      <td>po</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Põhja-Euroopas']</td>\n",
       "      <td>LOC</td>\n",
       "      <td>po</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Eesti']</td>\n",
       "      <td>LOC</td>\n",
       "      <td>po</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Soome', 'lahe', 'Soome', 'Vabariigiga']</td>\n",
       "      <td>LOC</td>\n",
       "      <td>po</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='ner', attributes=('nertag', 'name'), spans=SL[EnvelopingSpan(['Eesti', 'Vabariik'], [{'nertag': 'LOC', 'name': 'po'}]),\n",
       "EnvelopingSpan(['Põhja-Euroopas'], [{'nertag': 'LOC', 'name': 'po'}]),\n",
       "EnvelopingSpan(['Eesti'], [{'nertag': 'LOC', 'name': 'po'}]),\n",
       "EnvelopingSpan(['Soome', 'lahe', 'Soome', 'Vabariigiga'], [{'nertag': 'LOC', 'name': 'po'}])])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged2[0].ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span('Eesti', [{'normalized_form': None}])\n"
     ]
    }
   ],
   "source": [
    "for i, tekst in enumerate(textobject.words):\n",
    "    print(tekst)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-LOC',\n",
       " 'I-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'I-LOC',\n",
       " 'B-LOC',\n",
       " 'I-LOC',\n",
       " 'O']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged[0].ner[0].nertag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Eesti Vabariik on riik Põhja-Euroopas. Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Eesti Vabariik on riik Põhja-Euroopas. Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textobject"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
