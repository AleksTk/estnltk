{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "from pandas import read_csv\n",
    "from estnltk.taggers import RegexTagger\n",
    "\n",
    "from estnltk.spans import Span, SpanList\n",
    "from estnltk.layer import Layer\n",
    "from estnltk.finite_grammar.layer_graph import print_nodes\n",
    "import csv\n",
    "from estnltk.finite_grammar import PhraseListTagger\n",
    "\n",
    "from estnltk.taggers import GapTagger\n",
    "from estnltk.taggers import EnvelopingGapTagger\n",
    "from estnltk.taggers import MergeTagger\n",
    "\n",
    "from estnltk.layer_operations.flatten import flatten\n",
    "\n",
    "from estnltk.finite_grammar.layer_graph import layer_to_graph, plot_graph\n",
    "#from estnltk.finite_grammar.grammar import parse_graph\n",
    "#from estnltk.finite_grammar.layer_graph import graph_to_parse_trees\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "from estnltk.resolve_layer_dag import make_resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "specification = [\n",
    "    ('parem',),\n",
    "    ('vasak',), \n",
    "    ('eesmine',),\n",
    "    ('tagumine',),\n",
    "    ('külgmine',)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bodypart = [\n",
    "    ('neer',),\n",
    "    ('põlv',), \n",
    "    ('kops',),\n",
    "    ('aju',),\n",
    "    ('külgvatsake',)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location = [\n",
    "    ('tagasein',),\n",
    "    \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def location_decorator(text, span, phrase):\n",
    "    return {'match': phrase, 'grammar_symbol': 'LOCATION', \n",
    "            'form': span.form, 'partofspeech': span.partofspeech}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location_tagger = PhraseListTagger(layer_name='location',\n",
    "                              input_layer = 'morph_analysis',\n",
    "                               input_attribute='lemma',\n",
    "                             phrase_list=location,\n",
    "                               decorator = location_decorator,\n",
    "                             attributes=('match', 'grammar_symbol', 'form', 'partofspeech'),\n",
    "                             conflict_resolving_strategy= 'MAX'\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def specification_decorator(text, span, phrase):\n",
    "    return {'match': phrase, 'grammar_symbol': 'SPECIFICATION', \n",
    "            'form': span.form, 'partofspeech': span.partofspeech}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "specification_tagger = PhraseListTagger(layer_name='specification',\n",
    "                              input_layer = 'morph_analysis',\n",
    "                               input_attribute='lemma',\n",
    "                             phrase_list=specification,\n",
    "                               decorator = specification_decorator,\n",
    "                             attributes=('match', 'grammar_symbol', 'form', 'partofspeech'),\n",
    "                             conflict_resolving_strategy= 'MAX'\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bodypart_decorator(text, span, phrase):\n",
    "    return {'match': phrase, 'grammar_symbol': 'BODYPART', \n",
    "            'form': span.form, 'partofspeech': span.partofspeech}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bodypart_tagger = PhraseListTagger(layer_name='bodypart',\n",
    "                              input_layer = 'morph_analysis',\n",
    "                               input_attribute='lemma',\n",
    "                             phrase_list=bodypart,\n",
    "                               decorator = bodypart_decorator,\n",
    "                             attributes=('match', 'grammar_symbol', 'form', 'partofspeech'),\n",
    "                             conflict_resolving_strategy= 'MAX'\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taggers = {}\n",
    "taggers['bodypart'] = bodypart_tagger\n",
    "#taggers['location_tagger'] = location_tagger\n",
    "taggers['specification'] = specification_tagger\n",
    "taggers['location'] = location_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaps_decorator(text:str):\n",
    "    return {'gap_length':len(text), 'grammar_symbol': 'RANDOM_TEXT'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gaps_tagger = EnvelopingGapTagger(layer_name='gaps',\n",
    "                                 input_layers=['bodypart', \n",
    "                                               'location',\n",
    "                                               'specification'\n",
    "                                              ],\n",
    "                                 enveloped_layer='morph_analysis',\n",
    "                                 decorator=gaps_decorator,\n",
    "                                 attributes=['grammar_symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_tagger = MergeTagger(layer_name='grammar_tags',\n",
    "                           input_layers=['bodypart',\n",
    "                                       'location',\n",
    "                                         'specification',\n",
    "                                      'gaps'],\n",
    "                           attributes=('grammar_symbol', 'value', 'form', 'partofspeech'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag_sent(sent):\n",
    "    sent = Text(sent)\n",
    "    sent.analyse('morphology')\n",
    "    for tagger in taggers:\n",
    "        taggers[tagger].tag(sent)\n",
    "\n",
    "    gaps_tagger.tag(sent)\n",
    "    merge_tagger.tag(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Grammar:\n",
       "\tstart: COMP_MAIN\n",
       "\tterminals: BODYPART, LOCATION, SPECIFICATION\n",
       "\tnonterminals: COMPLEMENT, COMP_MAIN, MAIN\n",
       "\tlegal attributes: frozenset({'partofspeech', 'type', 'form', 'symboltype'})\n",
       "\tdepth_limit: inf\n",
       "\twidth_limit: inf\n",
       "Rules:\n",
       "\tCOMPLEMENT -> SPECIFICATION\t: 0, val: default_validator, dec: default_decorator, scoring: default_scoring\n",
       "\tMAIN -> BODYPART\t: 1, val: default_validator, dec: default_decorator, scoring: default_scoring\n",
       "\tMAIN -> LOCATION\t: 1, val: default_validator, dec: default_decorator, scoring: default_scoring\n",
       "\tCOMP_MAIN -> MAIN MAIN\t: 0, val: default_validator, dec: default_decorator, scoring: default_scoring"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.finite_grammar.grammar import Rule, Grammar\n",
    "\n",
    "rules = []\n",
    "\n",
    "\n",
    "\n",
    "rules.append(Rule('COMPLEMENT', 'SPECIFICATION'))\n",
    "#rules.append(Rule('COMPLEMENT', 'SPECIFICATION'))\n",
    "\n",
    "rules.append(Rule('MAIN', 'BODYPART', group = 'g1', priority = 1))\n",
    "rules.append(Rule('MAIN', 'LOCATION', group = 'g1', priority = 1))\n",
    "\n",
    "\n",
    "rules.append(Rule('COMP_MAIN', 'MAIN MAIN'))#, decorator = complement_decorator))\n",
    "\n",
    "grammar = Grammar(start_symbols=['COMP_MAIN'\n",
    "                                \n",
    "                                ], rules=rules,# max_depth = 4, \n",
    "                 legal_attributes=['form', 'type', 'symboltype', 'partofspeech'])\n",
    "grammar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from estnltk.taggers import GrammarParsingTagger\n",
    "parsing_tagger = GrammarParsingTagger(grammar=grammar,\n",
    "                              layer_of_tokens='grammar_tags',\n",
    "                              name_attribute='grammar_symbol', # the default\n",
    "                              layer_name='parse', # the default\n",
    "                              attributes=['form', 'partofspeech', 'type', 'grammar_symbol', \n",
    "                                          'span_count', 'name', '_priority_', '_group_'], # default: ()\n",
    "                              output_nodes=None, # by default grammar.start_symbols are used\n",
    "                              resolve_support_conflicts=True, # the default\n",
    "                              resolve_start_end_conflicts=True, # the default\n",
    "                              resolve_terminals_conflicts=True # the default\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from estnltk.taggers.grammar_parsing.grammar_parsing_tagger import GrammarParsingTagger\n",
    "parsing_tagger = GrammarParsingTagger(layer_name='parse',\n",
    "                                      attributes=['form', 'type',  'symboltype', 'partofspeech'],\n",
    "                                      layer_of_tokens='grammar_tags',\n",
    "                                      grammar=grammar,\n",
    "                                      output_nodes={'COMP_MAIN', 'COMPLEMENT', 'MAIN','COMP_'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 'põlve tagasein'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j = tag_sent(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>grammar_tags</td>\n",
       "      <td>grammar_symbol, value, form, partofspeech</td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>grammar_symbol</th>\n",
       "      <th>value</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><b>põlve</b></td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>BODYPART</td>\n",
       "      <td>None</td>\n",
       "      <td>[[sg g, sg g]]</td>\n",
       "      <td>[[S, S]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><b>tagasein</b></td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>None</td>\n",
       "      <td>[[sg n]]</td>\n",
       "      <td>[[S]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[SL[SL[Span(põlve, {'clitic': '', 'ending': '0', 'form': 'sg g', 'lemma': 'põli', 'partofspeech': 'S', 'root': 'põli', 'root_tokens': ('põli',)}),\n",
       "Span(põlve, {'clitic': '', 'ending': '0', 'form': 'sg g', 'lemma': 'põlv', 'partofspeech': 'S', 'root': 'põlv', 'root_tokens': ('põlv',)})]],\n",
       "SL[SL[Span(tagasein, {'clitic': '', 'ending': '0', 'form': 'sg n', 'lemma': 'tagasein', 'partofspeech': 'S', 'root': 'taga_sein', 'root_tokens': ('taga', 'sein')})]]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.grammar_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d3807827d5e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparsing_tagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/estnltk/estnltk/taggers/grammar_parsing/grammar_parsing_tagger.py\u001b[0m in \u001b[0;36mtag\u001b[0;34m(self, text, return_layer, status)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_layer must return a Layer instance'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/estnltk/estnltk/taggers/grammar_parsing/grammar_parsing_tagger.py\u001b[0m in \u001b[0;36m_make_layer\u001b[0;34m(self, text, layers)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         graph = layer_to_graph(layers[self.input_layer],\n\u001b[0;32m---> 41\u001b[0;31m                                name_attribute=self.name_attribute)\n\u001b[0m\u001b[1;32m     42\u001b[0m         graph = parse_graph(graph,\n\u001b[1;32m     43\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/estnltk/estnltk/finite_grammar/layer_graph.py\u001b[0m in \u001b[0;36mlayer_to_graph\u001b[0;34m(layer, name_attribute, attributes)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_starting_spans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_attribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTART_NODE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTerminalNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_ending_spans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_attribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/estnltk/estnltk/finite_grammar/layer_graph.py\u001b[0m in \u001b[0;36madd_edge\u001b[0;34m(self, u, v, **attr)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_start_end_to_nodes_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_parse_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_parse_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mebunch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/estnltk/estnltk/finite_grammar/layer_graph.py\u001b[0m in \u001b[0;36m_update_parse_trees\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_trees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTerminalNode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_trees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpanNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/networkx/classes/digraph.py\u001b[0m in \u001b[0;36madd_edge\u001b[0;34m(self, u, v, **attr)\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjlist_inner_dict_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_succ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_succ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjlist_inner_dict_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjlist_inner_dict_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/estnltk/estnltk/finite_grammar/layer_graph.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "parsing_tagger.tag(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
